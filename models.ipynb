{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('test.csv')\n",
    "test_data = test_data.drop('description', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "sampled_data = pd.read_csv('sampled_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ending_date = pd.to_datetime('2024-11-23')\n",
    "# def time_handling(df, ending_date = ending_date):\n",
    "#     df['host_since'] = pd.to_datetime(df['host_since'], errors='coerce')\n",
    "#     df['days_hosting'] = (ending_date - df['host_since']).dt.days\n",
    "#     df = df.drop('host_since', axis=1)\n",
    "#     return df\n",
    "\n",
    "def time_handling(df, ending_date=pd.to_datetime('2024-11-23')):\n",
    "    df['host_since'] = pd.to_datetime(df['host_since'], errors='coerce')\n",
    "    days_hosting = (ending_date - df['host_since']).dt.days\n",
    "    df['hosting_category'] = pd.cut(\n",
    "        days_hosting,\n",
    "        bins=[-float('inf'), 365, 3*365, float('inf')],  # Year thresholds\n",
    "        labels=[0, 1, 2]  # Encoded values\n",
    "    ).astype(int)\n",
    "    \n",
    "    # Drop the original 'host_since' column\n",
    "    df = df.drop('host_since', axis=1)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_feature_handling(df, ending_date = ending_date):\n",
    "    df['first_review'] = pd.to_datetime(df['first_review'], errors='coerce')\n",
    "    df['last_review'] = pd.to_datetime(df['last_review'], errors='coerce')\n",
    "    # df['days_since_first_review'] = (ending_date - df['first_review']).dt.days\n",
    "    # df['days_since_last_review'] = (ending_date - df['last_review']).dt.days\n",
    "    # df['days_since_first_review'] = df['days_since_first_review'].fillna(0)\n",
    "    # df['days_since_last_review'] = df['days_since_last_review'].fillna(0)\n",
    "    days_since_first_review = (ending_date - df['first_review']).dt.days\n",
    "    days_since_last_review = (ending_date - df['last_review']).dt.days\n",
    "    df['first_review_category'] = pd.cut(\n",
    "        days_since_first_review,\n",
    "        bins=[-float('inf'), 365, 3*365, float('inf')],  # Year thresholds\n",
    "        labels=[0, 1, 2]\n",
    "    ).fillna(0).astype(int)  # Fill NaN with 0 for missing first reviews\n",
    "\n",
    "    df['last_review_category'] = pd.cut(\n",
    "        days_since_last_review,\n",
    "        bins=[-float('inf'), 365, 3*365, float('inf')],  # Year thresholds\n",
    "        labels=[0, 1, 2]\n",
    "    ).fillna(0).astype(int)\n",
    "    df = df.drop(columns=['first_review', 'last_review'])\n",
    "    review_columns = [\n",
    "    'review_scores_rating', 'review_scores_accuracy', 'review_scores_cleanliness',\n",
    "    'review_scores_checkin', 'review_scores_communication', 'review_scores_location',\n",
    "    'review_scores_value', 'reviews_per_month', 'reviews']\n",
    "    df['missing_reviews'] = df[review_columns].isnull().any(axis=1)\n",
    "    df[review_columns] = df[review_columns].fillna(0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_host_response_time(df):\n",
    "    response_time_mapping = {\n",
    "    'within an hour': 0,\n",
    "    'within a few hours': 1,\n",
    "    'within a day': 2,\n",
    "    'a few days or more': 3\n",
    "}\n",
    "    df['host_response_time_encoded'] = df['host_response_time'].map(response_time_mapping)\n",
    "    # df = df.drop('host_response_time', axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used by host_response_rate, host_acceptance_rate, bedrooms, beds, bathrooms\n",
    "def fill_with_median(df, columns):\n",
    "    for column in columns:\n",
    "        if df[column].isnull().sum() > 0:\n",
    "            if df[column].dtype in ['float64', 'int64']:\n",
    "                global_mode = df[column].median()\n",
    "                df[column] = df[column].fillna(global_mode)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fill_with_median_train(df, columns):\n",
    "#     for column in columns:\n",
    "#         if df[column].isnull().sum() > 0:\n",
    "#             if df[column].dtype in ['float64', 'int64']:\n",
    "#                 df[column] = df[column].groupby('price')[column].transform(\n",
    "#                     lambda x: x.fillna(x.median()))\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def host_verification_handle(df):\n",
    "    df['host_verifications'] = df['host_verifications'].apply(lambda x: len(x) if isinstance(x, list) else 0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_model(sampled_data):\n",
    "    features = [\n",
    "    'host_response_rate', 'host_acceptance_rate',\n",
    "    'host_listings_count', 'host_total_listings_count', 'host_verifications',\n",
    "    'host_has_profile_pic', 'host_identity_verified', 'host_response_time_encoded'\n",
    "    ]\n",
    "    scaler = MinMaxScaler()\n",
    "    sampled_data[features] = scaler.fit_transform(sampled_data[features])\n",
    "    X = sampled_data[features]\n",
    "    y = sampled_data['host_is_superhost']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE)\n",
    "    model = LogisticRegression(random_state=RANDOM_STATE, max_iter=500, class_weight='balanced')\n",
    "    model.fit(X_train, y_train)\n",
    "    return model, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def host_is_superhost_handle(df, model, scaler):\n",
    "    features = [\n",
    "    'host_response_rate', 'host_acceptance_rate',\n",
    "    'host_listings_count', 'host_total_listings_count', 'host_verifications',\n",
    "    'host_has_profile_pic', 'host_identity_verified', 'host_response_time_encoded'\n",
    "    ]\n",
    "    missing_indices = df[df['host_is_superhost'].isnull()].index\n",
    "    X_missing = df.loc[missing_indices, features]\n",
    "    # missing_values_new = X_missing.isnull().sum()\n",
    "    # print(missing_values_new)\n",
    "    bool_features_pred = ['host_identity_verified', 'host_has_profile_pic']\n",
    "    X_missing[bool_features_pred] = X_missing[bool_features_pred].astype(int)\n",
    "    numerical_features = features\n",
    "    X_missing[numerical_features] = scaler.transform(X_missing[numerical_features])\n",
    "    predicted_values = model.predict(X_missing)\n",
    "    predicted_values = ['TRUE' if val == 1 else 'FALSE' for val in predicted_values]\n",
    "    df.loc[missing_indices, 'host_is_superhost'] = predicted_values\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove 'has_availability' and 'bathrooms_text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_pocessing_test_data(df):\n",
    "    df = time_handling(df)\n",
    "    df = review_feature_handling(df)\n",
    "    df = map_host_response_time(df)\n",
    "    median_columns = ['host_response_rate', 'host_acceptance_rate', 'bedrooms', 'beds', 'bathrooms']\n",
    "    df['host_response_time_encoded'] = df['host_response_time_encoded'].fillna(0)\n",
    "    df = fill_with_median(df, median_columns)\n",
    "    df = host_verification_handle(df)\n",
    "    model, scaler = get_log_model(sampled_data)\n",
    "    df = host_is_superhost_handle(df, model, scaler)\n",
    "    columns_to_drop = ['bathrooms_text', 'host_response_time', 'reviews']\n",
    "    df = df.drop(columns_to_drop, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_test_data = pre_pocessing_test_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_test_data = processed_test_data.drop(['name'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train_data = pre_pocessing_test_data(train_data)\n",
    "processed_train_data = processed_train_data.drop(['name'], axis = 1)\n",
    "processed_train_data = processed_train_data.drop(['description'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_property_type(df):\n",
    "    property_type_counts = df['property_type'].value_counts()\n",
    "    rare_threshold = 200\n",
    "    df['property_type'] = df['property_type'].apply(\n",
    "    lambda x: x if property_type_counts[x] >= rare_threshold else 'Other'\n",
    "    )\n",
    "    property_type_ranking = {\n",
    "    'Private room in home': 1,\n",
    "    'Private room in rental unit': 2,\n",
    "    'Private room in townhouse': 3,\n",
    "    'Private room in condo': 4,\n",
    "    'Room in hotel': 5,\n",
    "    'Entire rental unit': 6,\n",
    "    'Entire condo': 7,\n",
    "    'Entire townhouse': 8,\n",
    "    'Entire home': 9,\n",
    "    'Other': 10\n",
    "    }\n",
    "    df['property_type_encoded'] = df['property_type'].map(property_type_ranking)\n",
    "    df = df.drop('property_type', axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_room_type(df):\n",
    "    room_type_ranking = {\n",
    "    'Shared room': 1,\n",
    "    'Private room': 2,\n",
    "    'Hotel room': 3,\n",
    "    'Entire home/apt': 4\n",
    "    }\n",
    "    df['room_type_encoded'] = df['room_type'].map(room_type_ranking)\n",
    "    df = df.drop('room_type', axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "def calculate_amenities(amenities):\n",
    "    try:\n",
    "        amenities_list = ast.literal_eval(amenities) if isinstance(amenities, str) else []\n",
    "        return len(amenities_list)\n",
    "    except:\n",
    "        return 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neighbourhood_handling(df):\n",
    "    neighbourhood_ranking = {\n",
    "    'Staten Island': 1,\n",
    "    'Bronx': 2,\n",
    "    'Queens': 3,\n",
    "    'Brooklyn': 4,\n",
    "    'Manhattan': 5\n",
    "    }\n",
    "    df['neighbourhood_group_encoded'] = df['neighbourhood_group_cleansed'].map(neighbourhood_ranking)\n",
    "    df = df.drop(['neighbourhood_group_cleansed', 'neighbourhood_cleansed'], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def type_conversion(df):\n",
    "    conversion_list = ['host_has_profile_pic', 'host_identity_verified', 'instant_bookable', \n",
    "                   'missing_reviews', 'host_is_superhost', 'has_availability']\n",
    "    for col in conversion_list:\n",
    "        df[col] = df[col].apply(lambda x: 1 if x == 'TRUE' else 0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shallow_engineering_wrapper(df):\n",
    "    df = map_property_type(df)\n",
    "    df = map_room_type(df)\n",
    "    df['amenity_score'] = df['amenities'].apply(calculate_amenities)\n",
    "    df = df.drop('amenities', axis=1)\n",
    "    df = neighbourhood_handling(df)\n",
    "    df = type_conversion(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "shallow_engineered_test_data = shallow_engineering_wrapper(processed_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_train_data = shallow_engineering_wrapper(processed_train_data)\n",
    "# print(eng_train_data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data = pd.read_csv('./processed_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.inspection import permutation_importance\n",
    "# import matplotlib.pyplot as plt\n",
    "# perm_importance = permutation_importance(best_model, X_test, y_test, n_repeats=10, random_state=RANDOM_STATE)\n",
    "\n",
    "# # Display feature importance\n",
    "# feature_importance = pd.DataFrame({\n",
    "#     'Feature': X_test.columns,\n",
    "#     'Importance': perm_importance.importances_mean\n",
    "# }).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# print(\"\\nPermutation Feature Importance:\")\n",
    "# print(feature_importance)\n",
    "\n",
    "# # Plot feature importance\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# plt.barh(feature_importance['Feature'], feature_importance['Importance'])\n",
    "# plt.gca().invert_yaxis()\n",
    "# plt.title('Permutation Feature Importance')\n",
    "# plt.xlabel('Mean Importance')\n",
    "# plt.ylabel('Feature')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>price</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>host_response_rate</th>\n",
       "      <th>host_acceptance_rate</th>\n",
       "      <th>host_is_superhost</th>\n",
       "      <th>host_listings_count</th>\n",
       "      <th>host_total_listings_count</th>\n",
       "      <th>host_verifications</th>\n",
       "      <th>...</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>missing_reviews</th>\n",
       "      <th>days_hosting</th>\n",
       "      <th>days_since_first_review</th>\n",
       "      <th>days_since_last_review</th>\n",
       "      <th>host_response_time_encoded</th>\n",
       "      <th>property_type_encoded</th>\n",
       "      <th>room_type_encoded</th>\n",
       "      <th>amenity_score</th>\n",
       "      <th>neighbourhood_group_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>40.684560</td>\n",
       "      <td>-73.939870</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0</td>\n",
       "      <td>3472</td>\n",
       "      <td>2036.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>40.638991</td>\n",
       "      <td>-73.965739</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3.81</td>\n",
       "      <td>0</td>\n",
       "      <td>436</td>\n",
       "      <td>315.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>40.618810</td>\n",
       "      <td>-74.032380</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.14</td>\n",
       "      <td>0</td>\n",
       "      <td>846</td>\n",
       "      <td>149.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>40.673970</td>\n",
       "      <td>-73.953990</td>\n",
       "      <td>99.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>727.0</td>\n",
       "      <td>1336.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>4487</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>40.747180</td>\n",
       "      <td>-73.985390</td>\n",
       "      <td>93.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0</td>\n",
       "      <td>707.0</td>\n",
       "      <td>2453.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>3623</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  price   latitude  longitude  host_response_rate  \\\n",
       "0           0      4  40.684560 -73.939870               100.0   \n",
       "1           1      3  40.638991 -73.965739               100.0   \n",
       "2           2      3  40.618810 -74.032380               100.0   \n",
       "3           3      0  40.673970 -73.953990                99.0   \n",
       "4           4      2  40.747180 -73.985390                93.0   \n",
       "\n",
       "   host_acceptance_rate  host_is_superhost  host_listings_count  \\\n",
       "0                 100.0                  0                  2.0   \n",
       "1                  98.0                  0                  1.0   \n",
       "2                 100.0                  0                 52.0   \n",
       "3                  23.0                  0                727.0   \n",
       "4                  95.0                  0                707.0   \n",
       "\n",
       "   host_total_listings_count  host_verifications  ...  reviews_per_month  \\\n",
       "0                        2.0                   2  ...               0.52   \n",
       "1                        1.0                   2  ...               3.81   \n",
       "2                       55.0                   2  ...               2.14   \n",
       "3                     1336.0                   2  ...               0.00   \n",
       "4                     2453.0                   2  ...               0.00   \n",
       "\n",
       "   missing_reviews  days_hosting  days_since_first_review  \\\n",
       "0                0          3472                   2036.0   \n",
       "1                0           436                    315.0   \n",
       "2                0           846                    149.0   \n",
       "3                0          4487                      0.0   \n",
       "4                0          3623                      0.0   \n",
       "\n",
       "   days_since_last_review  host_response_time_encoded  property_type_encoded  \\\n",
       "0                   105.0                         2.0                      6   \n",
       "1                    82.0                         0.0                      2   \n",
       "2                    98.0                         0.0                      6   \n",
       "3                     0.0                         0.0                      2   \n",
       "4                     0.0                         0.0                      5   \n",
       "\n",
       "   room_type_encoded  amenity_score  neighbourhood_group_encoded  \n",
       "0                  4             32                            4  \n",
       "1                  2             37                            4  \n",
       "2                  4             34                            4  \n",
       "3                  2             14                            4  \n",
       "4                  3             24                            5  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_real = shallow_engineered_test_data.drop('id',axis=1)\n",
    "X_real[numerical_features] = scaler.transform(X_real[numerical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_real = X_real[X_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_real = best_model.predict(X_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_column = shallow_engineered_test_data['id']\n",
    "combined_df = pd.DataFrame({\n",
    "    'id': id_column,\n",
    "    'price': y_real\n",
    "})\n",
    "combined_df.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "loaded_classifier = XGBClassifier()\n",
    "loaded_classifier.load_model('booster_classifier.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = shallow_engineered_test_data.drop('id',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_pred.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "def get_modified_data(orig_data):\n",
    "    modified_data = orig_data.copy()\n",
    "    modified_data['weighted_availability'] = (\n",
    "        0.7 * orig_data['availability_90'] + \n",
    "        0.2 * orig_data['availability_60'] + \n",
    "        0.1 * orig_data['availability_30']\n",
    "    )\n",
    "\n",
    "    modified_data['log_minimum_nights'] = np.log1p(modified_data['minimum_nights'])\n",
    "    modified_data['min_nights_accommodates_interaction'] = modified_data['minimum_nights'] * modified_data['accommodates']\n",
    "\n",
    "    geo_features = orig_data[['longitude', 'latitude']]\n",
    "    kmeans = KMeans(n_clusters=5, random_state=RANDOM_STATE+1)\n",
    "\n",
    "    modified_data['location_cluster'] = kmeans.fit_predict(geo_features)\n",
    "    weights = {\n",
    "        'review_scores_location': 0.8,\n",
    "        'review_scores_cleanliness': 0.1,\n",
    "        'review_scores_communication': 0,\n",
    "        'review_scores_checkin': 0.1,\n",
    "        'review_scores_value': 0,\n",
    "        'review_scores_accuracy': 0\n",
    "    }\n",
    "\n",
    "    modified_data['weighted_review_score'] = (\n",
    "        modified_data['review_scores_location'] * weights['review_scores_location'] +\n",
    "        modified_data['review_scores_cleanliness'] * weights['review_scores_cleanliness'] +\n",
    "        modified_data['review_scores_communication'] * weights['review_scores_communication'] +\n",
    "        modified_data['review_scores_checkin'] * weights['review_scores_checkin'] +\n",
    "        modified_data['review_scores_value'] * weights['review_scores_value'] +\n",
    "        modified_data['review_scores_accuracy'] * weights['review_scores_accuracy']\n",
    "    )\n",
    "\n",
    "    modified_data['availability_acceptance_interaction'] = (\n",
    "        modified_data['weighted_availability'] * orig_data['host_acceptance_rate']\n",
    "    )\n",
    "    return modified_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Tools\\miniconda\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "modified_data = get_modified_data(shallow_engineered_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Tools\\miniconda\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "modified_data_train = get_modified_data(eng_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best Parameters: {'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 300}\n",
      "Accuracy: 0.5697452229299363\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.69      0.78       539\n",
      "           1       0.50      0.47      0.48       537\n",
      "           2       0.39      0.50      0.44       508\n",
      "           3       0.48      0.61      0.54       557\n",
      "           4       0.49      0.48      0.49       477\n",
      "           5       0.87      0.65      0.75       522\n",
      "           6       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.57      3140\n",
      "   macro avg       0.52      0.49      0.50      3140\n",
      "weighted avg       0.60      0.57      0.58      3140\n",
      "\n",
      "\n",
      "Root Mean Squared Error (RMSE): 0.7894608335081051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Tools\\miniconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Tools\\miniconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Tools\\miniconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# X = modified_data_train.drop(columns=['price'])\n",
    "# y = modified_data_train['price']\n",
    "\n",
    "X = eng_train_data.drop(columns=['price'])\n",
    "y = eng_train_data['price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y)\n",
    "\n",
    "numerical_features = X_train.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "\n",
    "model_xgb = XGBRegressor(objective='reg:squarederror', random_state=RANDOM_STATE)\n",
    "param_grid = {\n",
    "    'max_depth': [5,6,7],\n",
    "    'learning_rate': [0.1, 0.2],\n",
    "    'n_estimators': [250, 300],\n",
    "    # 'subsample': [0.8],\n",
    "    # 'colsample_bytree': [0.8]\n",
    "}\n",
    "grid_search = GridSearchCV(estimator=model_xgb, param_grid=param_grid, scoring='neg_mean_squared_error', cv=5, verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_rounded = np.round(y_pred).astype(int)\n",
    "y_pred_rounded = np.clip(y_pred_rounded, 0, None)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rounded))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_rounded))\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_rounded))\n",
    "print(\"\\nRoot Mean Squared Error (RMSE):\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_real = shallow_engineered_test_data.drop('id',axis=1)\n",
    "X_real = X_real[X_train.columns]\n",
    "y_real = best_model.predict(X_real)\n",
    "y_real_rounded = np.round(y_real).astype(int)\n",
    "y_real_rounded = np.clip(y_real_rounded, 0, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_column = shallow_engineered_test_data['id']\n",
    "combined_df = pd.DataFrame({\n",
    "    'id': id_column,\n",
    "    'price': y_real_rounded\n",
    "})\n",
    "combined_df.to_csv('predictions_reg0.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "Best Parameters: {'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 250}\n",
      "Accuracy: 0.5687898089171974\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.71      0.78       539\n",
      "           1       0.52      0.50      0.51       537\n",
      "           2       0.40      0.49      0.44       508\n",
      "           3       0.46      0.57      0.51       557\n",
      "           4       0.47      0.48      0.48       477\n",
      "           5       0.86      0.66      0.75       522\n",
      "\n",
      "    accuracy                           0.57      3140\n",
      "   macro avg       0.60      0.57      0.58      3140\n",
      "weighted avg       0.60      0.57      0.58      3140\n",
      "\n",
      "\n",
      "Root Mean Squared Error (RMSE): 0.7958891194418101\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "X = modified_data_train.drop(columns=['price'])\n",
    "y = modified_data_train['price']\n",
    "\n",
    "# X = eng_train_data.drop(columns=['price'])\n",
    "# y = eng_train_data['price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y)\n",
    "\n",
    "numerical_features = X_train.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "\n",
    "model_xgb = XGBRegressor(objective='reg:squarederror', random_state=RANDOM_STATE)\n",
    "param_grid = {\n",
    "    'max_depth': [7, 8,9],\n",
    "    'learning_rate': [0.1, 0.2],\n",
    "    'n_estimators': [200, 250, 300],\n",
    "    # 'subsample': [0.8],\n",
    "    # 'colsample_bytree': [0.8]\n",
    "}\n",
    "grid_search = GridSearchCV(estimator=model_xgb, param_grid=param_grid, scoring='neg_mean_squared_error', cv=5, verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_rounded = np.round(y_pred).astype(int)\n",
    "y_pred_rounded = np.clip(y_pred_rounded, 0, None)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rounded))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_rounded))\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_rounded))\n",
    "print(\"\\nRoot Mean Squared Error (RMSE):\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_real = modified_data.drop('id',axis=1)\n",
    "X_real = X_real[X_train.columns]\n",
    "y_real = best_model.predict(X_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_column = shallow_engineered_test_data['id']\n",
    "combined_df = pd.DataFrame({\n",
    "    'id': id_column,\n",
    "    'price': y_real\n",
    "})\n",
    "combined_df.to_csv('predictions_mode.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5964968152866242\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82       539\n",
      "           1       0.52      0.58      0.55       537\n",
      "           2       0.47      0.45      0.46       508\n",
      "           3       0.48      0.50      0.49       557\n",
      "           4       0.48      0.45      0.46       477\n",
      "           5       0.80      0.76      0.78       522\n",
      "\n",
      "    accuracy                           0.60      3140\n",
      "   macro avg       0.60      0.59      0.59      3140\n",
      "weighted avg       0.60      0.60      0.60      3140\n",
      "\n",
      "\n",
      "Root Mean Squared Error (RMSE): 0.8777141707897256\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "X = modified_data_train.drop(columns=['price'])\n",
    "y = modified_data_train['price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y)\n",
    "\n",
    "model_cb = CatBoostClassifier(iterations=1000, learning_rate=0.1, depth=10, verbose=0)\n",
    "model_cb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model_cb.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"\\nRoot Mean Squared Error (RMSE):\", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified_data_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import tensorflow as tf\n",
    "\n",
    "X = modified_data_train.drop('price', axis=1)\n",
    "y = modified_data_train['price']\n",
    "X = eng_train_data.drop('price', axis=1)\n",
    "y = eng_train_data['price']\n",
    "# categorical_columns = [col for col in X.columns if X[col].nunique() < 11]  # Example threshold\n",
    "# numerical_columns = [col for col in X.columns if col not in categorical_columns]\n",
    "# preprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         (\"num\", \"passthrough\", numerical_columns),  # Leave numerical columns as is\n",
    "#         (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_columns),  # Encode categorical columns\n",
    "#     ]\n",
    "# )\n",
    "# X_processed = preprocessor.fit_transform(X)\n",
    "X_train_nn, X_test_nn, y_train_nn, y_test_nn = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_nn = scaler.fit_transform(X_train_nn)\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X_processed)\n",
    "X_test_nn = scaler.transform(X_test_nn)\n",
    "\n",
    "X_train_nn = tf.convert_to_tensor(X_train_nn, dtype=tf.float32)\n",
    "X_test_nn = tf.convert_to_tensor(X_test_nn, dtype=tf.float32)\n",
    "y_train_nn = tf.convert_to_tensor(y_train_nn, dtype=tf.float32)\n",
    "y_test_nn = tf.convert_to_tensor(y_test_nn, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# y_one_hot = to_categorical(y, num_classes=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# def rmse_bins(y_true, y_pred):\n",
    "#     # Convert one-hot encoded y_true to bin indices\n",
    "#     true_bins = tf.argmax(y_true, axis=1)\n",
    "#     # Convert softmax probabilities y_pred to bin indices\n",
    "#     pred_bins = tf.argmax(y_pred, axis=1)\n",
    "#     # Compute RMSE\n",
    "#     return tf.sqrt(tf.reduce_mean(tf.square(tf.cast(true_bins - pred_bins, tf.float32))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(12556, 52), dtype=float32, numpy=\n",
       "array([[-0.6782533 , -0.7354472 , -4.0357533 , ...,  0.38300422,\n",
       "         0.7295359 , -1.2004305 ],\n",
       "       [ 0.58822495, -0.43631947, -2.5078557 , ..., -1.1885647 ,\n",
       "        -1.5620275 ,  1.5335017 ],\n",
       "       [ 0.27420738,  0.78496844,  0.3092058 , ...,  1.1687887 ,\n",
       "        -1.5620275 , -0.02615836],\n",
       "       ...,\n",
       "       [ 0.25857863,  2.5809655 ,  0.3569526 , ..., -0.40278026,\n",
       "         0.57769084,  1.2731451 ],\n",
       "       [-0.74440897, -0.6273661 ,  0.3569526 , ...,  0.38300422,\n",
       "         0.7003705 , -0.36563635],\n",
       "       [-0.14965107, -0.3475872 ,  0.3569526 , ..., -1.1885647 ,\n",
       "        -1.5620275 , -1.1045532 ]], dtype=float32)>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Tools\\miniconda\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "d:\\Tools\\miniconda\\Lib\\site-packages\\keras\\src\\layers\\activations\\leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "# Updated Model with Leaky ReLU\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Input Layer\n",
    "model.add(Dense(512, input_dim=X_train_nn.shape[1]))\n",
    "model.add(LeakyReLU(alpha=0.01))  # Leaky ReLU activation\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Hidden Layer 1\n",
    "model.add(Dense(256))\n",
    "model.add(LeakyReLU(alpha=0.01))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Hidden Layer 2\n",
    "model.add(Dense(128))\n",
    "model.add(LeakyReLU(alpha=0.01))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Output Layer\n",
    "model.add(Dense(1, activation='linear'))  # Linear activation for regression\n",
    "\n",
    "# Compile\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mae']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4760 - mae: 0.5323 - val_loss: 0.6476 - val_mae: 0.6057\n",
      "Epoch 2/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5039 - mae: 0.5448 - val_loss: 0.6506 - val_mae: 0.5996\n",
      "Epoch 3/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5089 - mae: 0.5510 - val_loss: 0.6439 - val_mae: 0.6010\n",
      "Epoch 4/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5133 - mae: 0.5560 - val_loss: 0.6550 - val_mae: 0.6076\n",
      "Epoch 5/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4922 - mae: 0.5441 - val_loss: 0.6510 - val_mae: 0.6034\n",
      "Epoch 6/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4823 - mae: 0.5353 - val_loss: 0.6571 - val_mae: 0.5928\n",
      "Epoch 7/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4715 - mae: 0.5299 - val_loss: 0.6683 - val_mae: 0.6241\n",
      "Epoch 8/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4845 - mae: 0.5359 - val_loss: 0.6538 - val_mae: 0.6066\n",
      "Epoch 9/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4772 - mae: 0.5337 - val_loss: 0.6636 - val_mae: 0.5990\n",
      "Epoch 10/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4881 - mae: 0.5413 - val_loss: 0.6775 - val_mae: 0.5915\n",
      "Epoch 11/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4948 - mae: 0.5401 - val_loss: 0.6515 - val_mae: 0.5869\n",
      "Epoch 12/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4997 - mae: 0.5459 - val_loss: 0.6518 - val_mae: 0.5838\n",
      "Epoch 13/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4890 - mae: 0.5390 - val_loss: 0.6364 - val_mae: 0.5721\n",
      "Epoch 14/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4804 - mae: 0.5347 - val_loss: 0.6405 - val_mae: 0.5968\n",
      "Epoch 15/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4891 - mae: 0.5400 - val_loss: 0.6528 - val_mae: 0.6060\n",
      "Epoch 16/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4949 - mae: 0.5439 - val_loss: 0.6372 - val_mae: 0.5950\n",
      "Epoch 17/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4736 - mae: 0.5315 - val_loss: 0.6580 - val_mae: 0.5855\n",
      "Epoch 18/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4545 - mae: 0.5213 - val_loss: 0.6385 - val_mae: 0.5953\n",
      "Epoch 19/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4698 - mae: 0.5271 - val_loss: 0.6481 - val_mae: 0.6048\n",
      "Epoch 20/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4695 - mae: 0.5316 - val_loss: 0.6640 - val_mae: 0.6027\n",
      "Epoch 21/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4883 - mae: 0.5431 - val_loss: 0.6691 - val_mae: 0.5975\n",
      "Epoch 22/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4686 - mae: 0.5296 - val_loss: 0.6525 - val_mae: 0.5968\n",
      "Epoch 23/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4594 - mae: 0.5248 - val_loss: 0.6552 - val_mae: 0.5863\n",
      "Epoch 24/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4662 - mae: 0.5296 - val_loss: 0.6520 - val_mae: 0.5879\n",
      "Epoch 25/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4681 - mae: 0.5307 - val_loss: 0.6589 - val_mae: 0.6063\n",
      "Epoch 26/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4802 - mae: 0.5359 - val_loss: 0.6466 - val_mae: 0.5921\n",
      "Epoch 27/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4594 - mae: 0.5224 - val_loss: 0.6489 - val_mae: 0.5817\n",
      "Epoch 28/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4595 - mae: 0.5201 - val_loss: 0.6681 - val_mae: 0.6203\n",
      "Epoch 29/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4855 - mae: 0.5446 - val_loss: 0.6476 - val_mae: 0.6016\n",
      "Epoch 30/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4441 - mae: 0.5154 - val_loss: 0.6516 - val_mae: 0.5988\n",
      "Epoch 31/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4685 - mae: 0.5310 - val_loss: 0.6675 - val_mae: 0.6079\n",
      "Epoch 32/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4518 - mae: 0.5165 - val_loss: 0.6464 - val_mae: 0.6107\n",
      "Epoch 33/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4577 - mae: 0.5255 - val_loss: 0.6473 - val_mae: 0.6061\n",
      "Epoch 34/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4664 - mae: 0.5286 - val_loss: 0.6835 - val_mae: 0.6041\n",
      "Epoch 35/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4732 - mae: 0.5368 - val_loss: 0.6647 - val_mae: 0.5884\n",
      "Epoch 36/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4779 - mae: 0.5357 - val_loss: 0.6761 - val_mae: 0.6218\n",
      "Epoch 37/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4506 - mae: 0.5217 - val_loss: 0.6513 - val_mae: 0.5976\n",
      "Epoch 38/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4584 - mae: 0.5239 - val_loss: 0.6452 - val_mae: 0.5952\n",
      "Epoch 39/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4408 - mae: 0.5185 - val_loss: 0.6444 - val_mae: 0.5906\n",
      "Epoch 40/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4518 - mae: 0.5193 - val_loss: 0.6571 - val_mae: 0.5941\n",
      "Epoch 41/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4610 - mae: 0.5247 - val_loss: 0.6700 - val_mae: 0.5912\n",
      "Epoch 42/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4505 - mae: 0.5216 - val_loss: 0.6563 - val_mae: 0.6069\n",
      "Epoch 43/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4549 - mae: 0.5215 - val_loss: 0.6552 - val_mae: 0.5976\n",
      "Epoch 44/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4321 - mae: 0.5114 - val_loss: 0.6674 - val_mae: 0.6200\n",
      "Epoch 45/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4645 - mae: 0.5284 - val_loss: 0.6554 - val_mae: 0.6112\n",
      "Epoch 46/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4301 - mae: 0.5101 - val_loss: 0.6532 - val_mae: 0.6103\n",
      "Epoch 47/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4539 - mae: 0.5233 - val_loss: 0.6580 - val_mae: 0.5930\n",
      "Epoch 48/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4399 - mae: 0.5132 - val_loss: 0.6569 - val_mae: 0.6011\n",
      "Epoch 49/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4522 - mae: 0.5228 - val_loss: 0.6590 - val_mae: 0.6074\n",
      "Epoch 50/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4371 - mae: 0.5135 - val_loss: 0.6571 - val_mae: 0.5849\n",
      "Epoch 51/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4647 - mae: 0.5325 - val_loss: 0.6699 - val_mae: 0.5924\n",
      "Epoch 52/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4437 - mae: 0.5173 - val_loss: 0.6575 - val_mae: 0.6031\n",
      "Epoch 53/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4356 - mae: 0.5133 - val_loss: 0.6625 - val_mae: 0.6084\n",
      "Epoch 54/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4462 - mae: 0.5207 - val_loss: 0.6574 - val_mae: 0.6035\n",
      "Epoch 55/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4610 - mae: 0.5223 - val_loss: 0.6519 - val_mae: 0.6036\n",
      "Epoch 56/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4474 - mae: 0.5189 - val_loss: 0.6610 - val_mae: 0.5990\n",
      "Epoch 57/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4308 - mae: 0.5114 - val_loss: 0.6680 - val_mae: 0.5910\n",
      "Epoch 58/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4316 - mae: 0.5074 - val_loss: 0.6572 - val_mae: 0.5974\n",
      "Epoch 59/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4350 - mae: 0.5093 - val_loss: 0.6596 - val_mae: 0.6021\n",
      "Epoch 60/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4582 - mae: 0.5249 - val_loss: 0.6592 - val_mae: 0.6021\n",
      "Epoch 61/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4535 - mae: 0.5254 - val_loss: 0.6706 - val_mae: 0.5922\n",
      "Epoch 62/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4396 - mae: 0.5179 - val_loss: 0.6580 - val_mae: 0.5943\n",
      "Epoch 63/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4358 - mae: 0.5103 - val_loss: 0.6681 - val_mae: 0.6007\n",
      "Epoch 64/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4375 - mae: 0.5153 - val_loss: 0.6654 - val_mae: 0.6114\n",
      "Epoch 65/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4198 - mae: 0.5002 - val_loss: 0.6588 - val_mae: 0.6027\n",
      "Epoch 66/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4514 - mae: 0.5205 - val_loss: 0.6563 - val_mae: 0.5935\n",
      "Epoch 67/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4571 - mae: 0.5202 - val_loss: 0.6599 - val_mae: 0.5868\n",
      "Epoch 68/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4291 - mae: 0.5064 - val_loss: 0.6585 - val_mae: 0.6053\n",
      "Epoch 69/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4188 - mae: 0.5025 - val_loss: 0.6566 - val_mae: 0.6037\n",
      "Epoch 70/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4162 - mae: 0.5027 - val_loss: 0.6513 - val_mae: 0.5929\n",
      "Epoch 71/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4249 - mae: 0.5061 - val_loss: 0.6538 - val_mae: 0.6027\n",
      "Epoch 72/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4402 - mae: 0.5151 - val_loss: 0.6435 - val_mae: 0.5856\n",
      "Epoch 73/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4331 - mae: 0.5095 - val_loss: 0.6542 - val_mae: 0.5962\n",
      "Epoch 74/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4111 - mae: 0.4989 - val_loss: 0.6536 - val_mae: 0.5971\n",
      "Epoch 75/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4509 - mae: 0.5180 - val_loss: 0.6648 - val_mae: 0.6233\n",
      "Epoch 76/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4215 - mae: 0.5005 - val_loss: 0.6547 - val_mae: 0.5937\n",
      "Epoch 77/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4126 - mae: 0.4957 - val_loss: 0.6581 - val_mae: 0.5982\n",
      "Epoch 78/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4125 - mae: 0.5006 - val_loss: 0.6498 - val_mae: 0.5945\n",
      "Epoch 79/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4068 - mae: 0.4932 - val_loss: 0.6627 - val_mae: 0.6093\n",
      "Epoch 80/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4227 - mae: 0.5026 - val_loss: 0.6718 - val_mae: 0.6061\n",
      "Epoch 81/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4339 - mae: 0.5133 - val_loss: 0.6479 - val_mae: 0.5910\n",
      "Epoch 82/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4306 - mae: 0.5062 - val_loss: 0.6667 - val_mae: 0.6194\n",
      "Epoch 83/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4237 - mae: 0.5045 - val_loss: 0.6617 - val_mae: 0.5892\n",
      "Epoch 84/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4352 - mae: 0.5142 - val_loss: 0.6674 - val_mae: 0.6208\n",
      "Epoch 85/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4140 - mae: 0.4983 - val_loss: 0.6654 - val_mae: 0.5836\n",
      "Epoch 86/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4535 - mae: 0.5200 - val_loss: 0.6565 - val_mae: 0.5831\n",
      "Epoch 87/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4214 - mae: 0.5050 - val_loss: 0.6480 - val_mae: 0.5887\n",
      "Epoch 88/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4087 - mae: 0.4930 - val_loss: 0.6529 - val_mae: 0.5944\n",
      "Epoch 89/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4366 - mae: 0.5099 - val_loss: 0.6602 - val_mae: 0.6143\n",
      "Epoch 90/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4206 - mae: 0.4998 - val_loss: 0.6583 - val_mae: 0.6124\n",
      "Epoch 91/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4443 - mae: 0.5195 - val_loss: 0.6458 - val_mae: 0.6042\n",
      "Epoch 92/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4134 - mae: 0.5000 - val_loss: 0.6632 - val_mae: 0.6144\n",
      "Epoch 93/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4398 - mae: 0.5152 - val_loss: 0.6647 - val_mae: 0.6139\n",
      "Epoch 94/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4088 - mae: 0.4954 - val_loss: 0.6560 - val_mae: 0.6069\n",
      "Epoch 95/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4123 - mae: 0.4974 - val_loss: 0.6479 - val_mae: 0.5849\n",
      "Epoch 96/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4123 - mae: 0.4984 - val_loss: 0.6429 - val_mae: 0.5803\n",
      "Epoch 97/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4019 - mae: 0.4917 - val_loss: 0.6572 - val_mae: 0.5918\n",
      "Epoch 98/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4157 - mae: 0.4991 - val_loss: 0.6563 - val_mae: 0.6041\n",
      "Epoch 99/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4279 - mae: 0.5074 - val_loss: 0.6676 - val_mae: 0.6198\n",
      "Epoch 100/100\n",
      "\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3857 - mae: 0.4791 - val_loss: 0.6544 - val_mae: 0.6026\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\n",
      "Root Mean Squared Error (RMSE): 0.8682290343284745\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train_nn, y_train_nn,\n",
    "    validation_split=0.2,  # Use 20% of training data for validation\n",
    "    epochs=100,           # Number of epochs\n",
    "    batch_size=32,        # Mini-batch size\n",
    "    verbose=1             # Display progress\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "# test_loss, test_mae, test_mse = model.evaluate(X_test_nn, y_test_nn, verbose=1)\n",
    "# print(f\"Test Loss: {test_loss:.4f}, Test MAE: {test_mae:.4f}, Test MSE: {test_mse:.4f}\")\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test_nn)\n",
    "\n",
    "# Round predictions to integers and clip negatives\n",
    "y_pred_rounded = np.round(y_pred).astype(int)\n",
    "y_pred_rounded = np.clip(y_pred_rounded, 0, None)  # Clip negatives to zero\n",
    "rmse = np.sqrt(mean_squared_error(y_test_nn, y_pred_rounded.flatten()))\n",
    "print(\"\\nRoot Mean Squared Error (RMSE):\", rmse)\n",
    "# print(\"Rounded Predictions:\", y_pred_rounded.flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0EAAAIjCAYAAADFthA8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB6V0lEQVR4nO3dd3xT9f7H8XeadC+gFNqy9wYR0AsoooCsi4LrysUrOK+KIo573QjurVf9ibhw4kAFFwhVAQVFUARBkCF7z9Ldpsn5/fFt0pYWaEvSpPT1fDzOIyfJyTmfhC9t3v1+z/fYLMuyBAAAAAA1REigCwAAAACAqkQIAgAAAFCjEIIAAAAA1CiEIAAAAAA1CiEIAAAAQI1CCAIAAABQoxCCAAAAANQohCAAAAAANQohCAAAAECNQggCAD8bM2aMmjZtWqnXTpw4UTabzbcFBZnNmzfLZrPpzTffrPJj22w2TZw40Xv/zTfflM1m0+bNm4/72qZNm2rMmDE+redE2goAoPwIQQBqLJvNVq5l/vz5gS61xhs3bpxsNps2bNhw1G3uuece2Ww2/f7771VYWcXt3LlTEydO1PLlywNdipcniD711FOBLgUAqoQj0AUAQKC88847Je6//fbbSk1NLfV4u3btTug4r776qtxud6Vee++99+rOO+88oeOfDEaNGqUXXnhB06ZN04QJE8rc5v3331enTp3UuXPnSh/nX//6ly699FKFh4dXeh/Hs3PnTk2aNElNmzbVKaecUuK5E2krAIDyIwQBqLEuu+yyEvcXL16s1NTUUo8fKTs7W1FRUeU+TmhoaKXqkySHwyGHgx/Vp59+ulq2bKn333+/zBD0008/adOmTXrsscdO6Dh2u112u/2E9nEiTqStAADKj+FwAHAMffv2VceOHfXrr7+qT58+ioqK0t133y1J+uyzzzR06FClpKQoPDxcLVq00IMPPiiXy1ViH0ee51F86NErr7yiFi1aKDw8XD169NDSpUtLvLasc4JsNptuvPFGzZw5Ux07dlR4eLg6dOigr7/+ulT98+fPV/fu3RUREaEWLVpoypQp5T7P6IcfftDFF1+sxo0bKzw8XI0aNdItt9yinJycUu8vJiZGO3bs0PDhwxUTE6PExETdfvvtpT6LtLQ0jRkzRvHx8apVq5ZGjx6ttLS049Yimd6gP//8U8uWLSv13LRp02Sz2TRy5Ejl5+drwoQJ6tatm+Lj4xUdHa0zzzxT8+bNO+4xyjonyLIsPfTQQ2rYsKGioqJ09tln648//ij12oMHD+r2229Xp06dFBMTo7i4OA0ePFgrVqzwbjN//nz16NFDknTFFVd4h1x6zocq65ygrKws3XbbbWrUqJHCw8PVpk0bPfXUU7Isq8R2FWkXlbV3715dddVVql+/viIiItSlSxe99dZbpbb74IMP1K1bN8XGxiouLk6dOnXS//73P+/zTqdTkyZNUqtWrRQREaGEhASdccYZSk1N9VmtAHAs/HkRAI7jwIEDGjx4sC699FJddtllql+/viTzhTkmJka33nqrYmJi9N1332nChAlKT0/Xk08+edz9Tps2TRkZGfr3v/8tm82mJ554QhdccIE2btx43B6BhQsX6tNPP9UNN9yg2NhYPf/887rwwgu1detWJSQkSJJ+++03DRo0SMnJyZo0aZJcLpceeOABJSYmlut9T58+XdnZ2br++uuVkJCgJUuW6IUXXtD27ds1ffr0Etu6XC4NHDhQp59+up566il98803evrpp9WiRQtdf/31kkyYOP/887Vw4UJdd911ateunWbMmKHRo0eXq55Ro0Zp0qRJmjZtmk499dQSx/7oo4905plnqnHjxtq/f79ee+01jRw5Utdcc40yMjL0+uuva+DAgVqyZEmpIWjHM2HCBD300EMaMmSIhgwZomXLluncc89Vfn5+ie02btyomTNn6uKLL1azZs20Z88eTZkyRWeddZZWr16tlJQUtWvXTg888IAmTJiga6+9VmeeeaYkqVevXmUe27IsnXfeeZo3b56uuuoqnXLKKZozZ47+85//aMeOHXr22WdLbF+edlFZOTk56tu3rzZs2KAbb7xRzZo10/Tp0zVmzBilpaXp5ptvliSlpqZq5MiR6tevnx5//HFJ0po1a7Ro0SLvNhMnTtSjjz6qq6++WqeddprS09P1yy+/aNmyZRowYMAJ1QkA5WIBACzLsqyxY8daR/5YPOussyxJ1ssvv1xq++zs7FKP/fvf/7aioqKs3Nxc72OjR4+2mjRp4r2/adMmS5KVkJBgHTx40Pv4Z599ZkmyvvjiC+9j999/f6maJFlhYWHWhg0bvI+tWLHCkmS98MIL3seGDRtmRUVFWTt27PA+tn79esvhcJTaZ1nKen+PPvqoZbPZrC1btpR4f5KsBx54oMS2Xbt2tbp16+a9P3PmTEuS9cQTT3gfKygosM4880xLkjV16tTj1tSjRw+rYcOGlsvl8j729ddfW5KsKVOmePeZl5dX4nWHDh2y6tevb1155ZUlHpdk3X///d77U6dOtSRZmzZtsizLsvbu3WuFhYVZQ4cOtdxut3e7u+++25JkjR492vtYbm5uibosy/xbh4eHl/hsli5detT3e2Rb8XxmDz30UIntLrroIstms5VoA+VtF2XxtMknn3zyqNs899xzliTr3Xff9T6Wn59v9ezZ04qJibHS09Mty7Ksm2++2YqLi7MKCgqOuq8uXbpYQ4cOPWZNAOBPDIcDgOMIDw/XFVdcUerxyMhI73pGRob279+vM888U9nZ2frzzz+Pu99//OMfql27tve+p1dg48aNx31t//791aJFC+/9zp07Ky4uzvtal8ulb775RsOHD1dKSop3u5YtW2rw4MHH3b9U8v1lZWVp//796tWrlyzL0m+//VZq++uuu67E/TPPPLPEe5k1a5YcDoe3Z0gy5+DcdNNN5apHMudxbd++Xd9//733sWnTpiksLEwXX3yxd59hYWGSJLfbrYMHD6qgoEDdu3cvcyjdsXzzzTfKz8/XTTfdVGII4fjx40ttGx4erpAQ82vV5XLpwIEDiomJUZs2bSp8XI9Zs2bJbrdr3LhxJR6/7bbbZFmWZs+eXeLx47WLEzFr1iwlJSVp5MiR3sdCQ0M1btw4ZWZmasGCBZKkWrVqKSsr65hD22rVqqU//vhD69evP+G6AKAyCEEAcBwNGjTwfqku7o8//tCIESMUHx+vuLg4JSYmeidVOHz48HH327hx4xL3PYHo0KFDFX6t5/We1+7du1c5OTlq2bJlqe3KeqwsW7du1ZgxY1SnTh3veT5nnXWWpNLvLyIiotQwu+L1SNKWLVuUnJysmJiYEtu1adOmXPVI0qWXXiq73a5p06ZJknJzczVjxgwNHjy4RKB866231LlzZ+/5JomJifrqq6/K9e9S3JYtWyRJrVq1KvF4YmJiieNJJnA9++yzatWqlcLDw1W3bl0lJibq999/r/Bxix8/JSVFsbGxJR73zFjoqc/jeO3iRGzZskWtWrXyBr2j1XLDDTeodevWGjx4sBo2bKgrr7yy1HlJDzzwgNLS0tS6dWt16tRJ//nPf4J+anMAJxdCEAAcR/EeEY+0tDSdddZZWrFihR544AF98cUXSk1N9Z4DUZ5pjo82C5l1xAnvvn5tebhcLg0YMEBfffWV7rjjDs2cOVOpqaneE/iPfH9VNaNavXr1NGDAAH3yySdyOp364osvlJGRoVGjRnm3effddzVmzBi1aNFCr7/+ur7++mulpqbqnHPO8ev004888ohuvfVW9enTR++++67mzJmj1NRUdejQocqmvfZ3uyiPevXqafny5fr888+95zMNHjy4xLlfffr00V9//aU33nhDHTt21GuvvaZTTz1Vr732WpXVCaBmY2IEAKiE+fPn68CBA/r000/Vp08f7+ObNm0KYFVF6tWrp4iIiDIvLnqsC456rFy5UuvWrdNbb72lyy+/3Pv4icze1aRJE3377bfKzMws0Ru0du3aCu1n1KhR+vrrrzV79mxNmzZNcXFxGjZsmPf5jz/+WM2bN9enn35aYgjb/fffX6maJWn9+vVq3ry59/F9+/aV6l35+OOPdfbZZ+v1118v8XhaWprq1q3rvV+emfmKH/+bb75RRkZGid4gz3BLT31VoUmTJvr999/ldrtL9AaVVUtYWJiGDRumYcOGye1264YbbtCUKVN03333eXsi69SpoyuuuEJXXHGFMjMz1adPH02cOFFXX311lb0nADUXPUEAUAmev7gX/wt7fn6+XnrppUCVVILdblf//v01c+ZM7dy50/v4hg0bSp1HcrTXSyXfn2VZJaY5rqghQ4aooKBAkydP9j7mcrn0wgsvVGg/w4cPV1RUlF566SXNnj1bF1xwgSIiIo5Z+88//6yffvqpwjX3799foaGheuGFF0rs77nnniu1rd1uL9XjMn36dO3YsaPEY9HR0ZJUrqnBhwwZIpfLpRdffLHE488++6xsNlu5z+/yhSFDhmj37t368MMPvY8VFBTohRdeUExMjHeo5IEDB0q8LiQkxHsB27y8vDK3iYmJUcuWLb3PA4C/0RMEAJXQq1cv1a5dW6NHj9a4ceNks9n0zjvvVOmwo+OZOHGi5s6dq969e+v666/3fpnu2LGjli9ffszXtm3bVi1atNDtt9+uHTt2KC4uTp988skJnVsybNgw9e7dW3feeac2b96s9u3b69NPP63w+TIxMTEaPny497yg4kPhJOnvf/+7Pv30U40YMUJDhw7Vpk2b9PLLL6t9+/bKzMys0LE81zt69NFH9fe//11DhgzRb7/9ptmzZ5fo3fEc94EHHtAVV1yhXr16aeXKlXrvvfdK9CBJUosWLVSrVi29/PLLio2NVXR0tE4//XQ1a9as1PGHDRums88+W/fcc482b96sLl26aO7cufrss880fvz4EpMg+MK3336r3NzcUo8PHz5c1157raZMmaIxY8bo119/VdOmTfXxxx9r0aJFeu6557w9VVdffbUOHjyoc845Rw0bNtSWLVv0wgsv6JRTTvGeP9S+fXv17dtX3bp1U506dfTLL7/o448/1o033ujT9wMAR0MIAoBKSEhI0JdffqnbbrtN9957r2rXrq3LLrtM/fr108CBAwNdniSpW7dumj17tm6//Xbdd999atSokR544AGtWbPmuLPXhYaG6osvvtC4ceP06KOPKiIiQiNGjNCNN96oLl26VKqekJAQff755xo/frzeffdd2Ww2nXfeeXr66afVtWvXCu1r1KhRmjZtmpKTk3XOOeeUeG7MmDHavXu3pkyZojlz5qh9+/Z69913NX36dM2fP7/CdT/00EOKiIjQyy+/rHnz5un000/X3LlzNXTo0BLb3X333crKytK0adP04Ycf6tRTT9VXX32lO++8s8R2oaGheuutt3TXXXfpuuuuU0FBgaZOnVpmCPJ8ZhMmTNCHH36oqVOnqmnTpnryySd12223Vfi9HM/XX39d5sVVmzZtqo4dO2r+/Pm688479dZbbyk9PV1t2rTR1KlTNWbMGO+2l112mV555RW99NJLSktLU1JSkv7xj39o4sSJ3mF048aN0+eff665c+cqLy9PTZo00UMPPaT//Oc/Pn9PAFAWmxVMf7YEAPjd8OHDmZ4YAFCjcU4QAJzEcnJyStxfv369Zs2apb59+wamIAAAggA9QQBwEktOTtaYMWPUvHlzbdmyRZMnT1ZeXp5+++23Ute+AQCgpuCcIAA4iQ0aNEjvv/++du/erfDwcPXs2VOPPPIIAQgAUKPREwQAAACgRuGcIAAAAAA1CiEIAAAAQI1Src8Jcrvd2rlzp2JjY2Wz2QJdDgAAAIAAsSxLGRkZSklJ8V6X7GiqdQjauXOnGjVqFOgyAAAAAASJbdu2qWHDhsfcplqHoNjYWEnmjcbFxQW0FqfTqblz5+rcc89VaGhoQGtB9ULbQWXQblAZtBtUFm0HlVHV7SY9PV2NGjXyZoRjqdYhyDMELi4uLihCUFRUlOLi4vjhgAqh7aAyaDeoDNoNKou2g8oIVLspz2kyTIwAAAAAoEYhBAEAAACoUQhBAAAAAGqUan1OEAAAAIKPy+WS0+kMdBkIMKfTKYfDodzcXLlcrhPen91ul8Ph8MmlcQhBAAAA8JnMzExt375dlmUFuhQEmGVZSkpK0rZt23x2Tc+oqCglJycrLCzshPZDCAIAAIBPuFwubd++XVFRUUpMTORi9jWc2+1WZmamYmJijnvx0uOxLEv5+fnat2+fNm3apFatWp3QPglBAAAA8Amn0ynLspSYmKjIyMhAl4MAc7vdys/PV0RExAmHIEmKjIxUaGiotmzZ4t1vZTExAgAAAHyKHiD4iy/ClEQIAgAAAFDDEIIAAAAA1CiEIAAAAMDHmjZtqueee67c28+fP182m01paWl+qwlFAh6CduzYocsuu0wJCQmKjIxUp06d9MsvvwS6LAAAANQANpvtmMvEiRMrtd+lS5fq2muvLff2vXr10q5duxQfH1+p45UXYcsI6Oxwhw4dUu/evXX22Wdr9uzZSkxM1Pr161W7du1AlgUAAIAaYteuXd71Dz/8UBMmTNDatWu9j8XExHjXLcuSy+WSw3H8r9CJiYkVqiMsLExJSUkVeg0qL6A9QY8//rgaNWqkqVOn6rTTTlOzZs107rnnqkWLFoEsCwAAAD5gWVJWVmCW8l6rNSkpybvEx8fLZrN57//555+KjY3V7Nmz1a1bN4WHh2vhwoX666+/dP7556t+/fqKiYlRjx499M0335TY75HD4Ww2m1577TWNGDFCUVFRatWqlT7//HPv80f20Lz55puqVauW5syZo3bt2ikmJkaDBg0qEdoKCgo0btw41apVSwkJCbrjjjs0evRoDR8+vLL/ZDp06JAuv/xy1a5dW1FRURo8eLDWr1/vfX7Lli0aNmyYateurejoaHXo0EGzZs3yvnbUqFHeKdLbtGmj9957r9K1+FNAe4I+//xzDRw4UBdffLEWLFigBg0a6IYbbtA111xT5vZ5eXnKy8vz3k9PT5dk5qR3Op1VUvPReI4f6DpQ/dB2UBm0G1QG7QaVVd6247lOkNvtltvtVlaWFBcXmL+5p6e7FR1dsde43e4yb++880498cQTat68uWrXrq1t27Zp0KBBevDBBxUeHq533nlHw4YN05o1a9S4cWPv/jyfhcekSZP02GOP6fHHH9eLL76oUaNGadOmTapTp06JY3qW7OxsPfnkk3rrrbcUEhKiyy+/XLfddpveffddSdJjjz2m9957T6+//rratWun559/XjNnzlTfvn1LHPdo77GsbUaPHq0NGzZo5syZiouL05133qkhQ4Zo1apVCg0N1Q033KD8/HzNnz9f0dHRWr16taKiouR2u3Xvvfdq9erV+uqrr1S3bl2tX79eBw8eLPU5nAi32y3LsuR0OmW320s8V5GfbQENQRs3btTkyZN166236u6779bSpUs1btw4hYWFafTo0aW2f/TRRzVp0qRSj8+dO1dRUVFVUfJxpaamBroEVFO0HVQG7QaVQbtBZR2v7TgcDiUlJSkzM1P5+fnKypKkWlVRWinp6elyuSr2mtzcXFmW5f1De3Z2tiTpjjvu0Omnn+7drlmzZmrWrJn3/u23365PPvlEH330kfc8ILfbrdzcXO++JOnSSy/V0KFDvft84YUXNH/+fPXv3997rIyMDIWEhCg3N1dOp1NPPvmk91hXXnmlnnzySe8+X3jhBY0fP179+vWTJD388MP66quvVFBQUOK4xR15nOL++usvffHFF/r666/VpUsXSdLkyZPVsWNHvf/++xo+fLg2b96s8847T02aNJEk9enTR5L5vDdu3KgOHTqodevWkuT9zDIyMsr1+ZdHfn6+cnJy9P3336ugoKDM91YeAQ1Bbrdb3bt31yOPPCJJ6tq1q1atWqWXX365zBB011136dZbb/XeT09PV6NGjXTuuecqLi6uyuouy+LFLn355e+67LJOats2oB8rqhmn06nU1FQNGDBAoaGhgS4H1QTtBpVBu0Fllbft5Obmatu2bYqJiVFERIRiY02PTCBERcWpotdsjYiIkM1m836v9PyR/cwzzyzxXTMzM1OTJk3SrFmztGvXLhUUFCgnJ0f79u3zbhcSEqKIiIgSr+vevbv3flxcnOLi4pSZmam4uDjvsWJjYxUXF6eIiAhFRUV5w4hkwpfnGIcPH9bevXtL1da9e3e53e6jfjc+8jjFbdu2TQ6HQ+ecc463lyUuLk5t2rTRli1bFBcXp5tvvlljx47V999/r379+umCCy5Q586dJUk33nijLr74Yq1atUoDBgzQeeedp06dOik2NtZnF9DNzc1VZGSk+vTpo4iIiBLPHS34lSWg39aTk5PVvn37Eo+1a9dOn3zySZnbh4eHKzw8vNTjoaGhAf9h/txzdn366Wlq0MClTp3sx38BcIRgaMeofmg3qAzaDSrreG3H5XLJZrMpJCTE28sQG1tV1Z04T81H3sbGxpboNfnvf/+r1NRUPfXUU2rZsqUiIyN10UUXyel0ltjO81l4hIeHl3rec5zix/QsoaGhJba32+2yLKvM7Yvv88jjHu09HrnNsZ7z7PPaa6/V4MGD9dVXX2nu3Ll67LHH9PTTT+umm27S0KFDtWXLFs2aNUupqak699xzdfXVV+t///vfUeupqJCQENlstjLbYkV+rgV0YoTevXuXmH1DktatW+ftXqtOwsLMbbFTlgAAAHASWrRokcaMGaMRI0aoU6dOSkpK0ubNm6u0hvj4eNWvX19Lly71PuZyubRs2bJK77Ndu3YqKCjQzz//7H3swIEDWrt2bYmOi0aNGum6667Tp59+qttuu02vvvqq97nExESNHj1a7777rp555hm99dZbla7HnwLaE3TLLbeoV69eeuSRR3TJJZdoyZIleuWVV/TKK68EsqxK8XRQEYIAAABObq1atdKnn36qYcOGyWaz6b777vPZif8VcdNNN+nRRx9Vy5Yt1bZtW73wwgs6dOhQuYaerVy5UrHFuulsNpu6dOmi888/X9dcc42mTJmi2NhY3XnnnWrQoIHOP/98SdL48eM1ePBgtW7dWocOHdK8efPUrl07SdKECRPUrVs3dejQQXl5efrqq6+85wcFm4CGoB49emjGjBm666679MADD6hZs2Z67rnnNGrUqECWVSnh4WYeRkIQAADAye2ZZ57RlVdeqV69eqlu3bq64447KnQ+iq/ccccd2r17ty6//HLZ7XZde+21GjhwYKlZ08rimdDAw263q6CgQFOnTtXNN9+sv//978rPz1efPn00a9Ys71Azl8ulsWPHavv27YqLi9OgQYP07LPPSjLXOrrrrru0efNmRUZG6owzztDrr7/u+zfuAzbLKu8s6sEnPT1d8fHxOnz4cMAnRhg3zqUXXrDrP/9x6YknOCcI5ed0OjVr1iwNGTKEMfooN9oNKoN2g8oqb9vJzc3Vpk2b1KxZs1InrcP/3G632rVrp0suuUQPPvhgoMuR2+1Wenq64uLifHZO0LHaWEWyAdOY+YjnnCAuvQAAAICqsGXLFs2dO1dnnXWW8vLy9OKLL2rTpk365z//GejSgl5AJ0Y4mXBOEAAAAKpSSEiI3nzzTfXo0UO9e/fWypUr9c0333jP0cHR0RPkI0UhyDdzoAMAAADH0qhRIy1atCjQZVRL9AT5CD1BAAAAQPVACPIRQhAAAABQPRCCfIQpsgEAAIDqgRDkI57Z4fLzA1sHAAAAgGMjBPkIw+EAAACA6oEQ5COEIAAAAKB6IAT5iGc4HCEIAACg5unbt6/Gjx/vvd+0aVM999xzx3yNzWbTzJkzT/jYvtpPTUII8hGuEwQAAFD9DBs2TIMGDSrzuR9++EE2m02///57hfe7dOlSXXvttSdaXgkTJ07UKaecUurxXbt2afDgwT491pHefPNN1apVy6/HqEqEIB9hOBwAAED1c9VVVyk1NVXbt28v9dzUqVPVvXt3de7cucL7TUxMVFRUlC9KPK6kpCSFe76MolwIQT7iaXfMDgcAAFDIsqSCrMAsllWuEv/+978rMTFRb775ZonHMzMzNX36dF111VU6cOCARo4cqQYNGigqKkqdOnXS+++/f8z9Hjkcbv369erTp48iIiLUvn17paamlnrNHXfcodatWysqKkrNmzfXfffdJ6fTKcn0xEyaNEkrVqyQzWaTzWbz1nzkcLiVK1fqnHPOUWRkpBISEnTttdcqMzPT+/yYMWM0fPhwPfXUU0pOTlZCQoLGjh3rPVZlbN26Veeff75iYmIUFxenSy65RHv27PE+v2LFCp199tmKjY1VXFycunXrpl9++UWStGXLFg0bNky1a9dWdHS0OnTooFmzZlW6lvJw+HXvNUhYmPmPRggCAAAo5MqWPooJzLEvyZQc0cfdzOFw6PLLL9ebb76pe+65RzabObVh+vTpcrlcGjlypDIzM9WtWzfdcccdiouL01dffaV//etfatGihU477bTjHsPtduuCCy5Q/fr19fPPP+vw4cMlzh/yiI2N1ZtvvqmUlBStXLlS11xzjWJjY/Xf//5X//jHP7Rq1Sp9/fXX+uabbyRJ8fHxpfaRlZWlgQMHqmfPnlq6dKn27t2rq6++WjfeeGOJoDdv3jwlJydr3rx52rBhg/7xj3/olFNO0TXXXHPc91PW+/MEoAULFqigoEBjx47VyJEjveFs1KhR6tq1qyZPniy73a7ly5crNDRUkjR27Fjl5+fr+++/V3R0tFavXq2YGP+2G0KQjzAcDgAAoHq68sor9eSTT2rBggXq27evJDMU7sILL1R8fLzi4+N1++23e7e/6aabNGfOHH300UflCkHffPON/vzzT82ZM0cpKSmSpEceeaTUeTz33nuvd71p06a6/fbb9cEHH+i///2vIiMjFRMTI4fDoaSkpKMea9q0acrNzdXbb7+t6GgTAl988UUNGzZMjz/+uOrXry9Jql27tl588UXZ7Xa1bdtWQ4cO1bffflupEPTtt99q5cqV2rRpkxo1aiRJevvtt9WhQwctW7ZMffv21datW/Wf//xHbdu2lSS1atXK+/qtW7fqwgsvVKdOnSRJzZs3r3ANFUUI8hFCEAAAwBHsUaZHJlDHLqe2bduqV69eeuONN9S3b19t2LBBP/zwgx544AFJksvl0iOPPKKPPvpIO3bsUH5+vvLy8sp9zs+aNWvUqFEjbwCSpJ49e5ba7sMPP9Tzzz+vv/76S5mZmSooKFBcXFy534fnWF26dPEGIEnq3bu33G631q5d6w1BHTp0kN1u926TnJyslStXVuhYxY/ZqFEjbwCSpPbt26tWrVpat26d+vbtq1tvvVVXX3213nnnHfXv318XX3yxWrRoIUkaN26crr/+es2dO1f9+/fXhRdeWKnzsCqCc4J8hBAEAABwBJvNDEkLxGKr2Iy9V111lT755BNlZGRo6tSpatGihc466yxJ0pNPPqn//e9/uuOOOzRv3jwtX75cAwcOVL4Pz4P46aefNGrUKA0ZMkRffvmlfvvtN91zzz0+PUZxnqFoHjabTW632y/HkszMdn/88YeGDh2q7777Tu3bt9eMGTMkSVdffbU2btyof/3rX1q5cqW6d++uF154wW+1SIQgn/GEIJfLJpcrsLUAAACgYi655BKFhIRo2rRpevvtt3XllVd6zw9atGiRzj//fF122WXq0qWLmjdvrnXr1pV73+3atdO2bdu0a9cu72OLFy8usc2PP/6oJk2a6J577lH37t3VqlUrbdmypcQ2YWFhch3ni2a7du20YsUKZWVleR9btGiRQkJC1KZNm3LXXBGe97dt2zbvY6tXr1ZaWlqJY7Zu3Vq33HKL5s6dqwsuuEBTp071PteoUSNdd911+vTTT3Xbbbfp1Vdf9UutHoQgHyk+KyG9QQAAANVLTEyM/vGPf+iuu+7Srl27NGbMGO9zrVq1Umpqqn788UetWbNG//73v0vMfHY8/fv3V+vWrTV69GitWLFCP/zwg+65554S27Rq1Upbt27VBx98oL/++kvPP/+8t6fEo2nTptq0aZOWL1+u/fv3K6+ML52jRo1SRESERo8erVWrVmnevHm66aab9K9//cs7FK6yXC6Xli9fXmJZs2aN+vfvr06dOmnUqFFatmyZlixZossvv1xnnXWWunbtqpycHN14442aP3++tmzZokWLFmnp0qVq166dJGn8+PGaM2eONm3apGXLlmnevHne5/yFEOQjhCAAAIDq7aqrrtKhQ4c0cODAEufv3HvvvTr11FM1cOBA9e3bV0lJSRo+fHi59xsSEqIZM2YoJydHp512mq6++mo9/PDDJbY577zzdMstt+jGG2/UKaecoh9//FH33XdfiW0uvPBCDRo0SGeffbYSExPLnKY7KipKc+bM0cGDB9WjRw9ddNFF6tevn1588cWKfRhlyMzMVNeuXUssw4YNk81m02effabatWurT58+6t+/v5o3b+6tz26368CBA7r88svVunVrXXLJJRo8eLAmTZokyYSrsWPHql27dho0aJBat26tl1566YTrPRabZZVzEvUglJ6ervj4eB0+fLjCJ435Wn6+UxERDlmWTbt2SceYtAMowel0atasWRoyZEip8bnA0dBuUBm0G1RWedtObm6uNm3apGbNmikiIqIKK0QwcrvdSk9PV1xcnEJCfNP3cqw2VpFsQE+Qj9hsUmioOZmMniAAAAAgeBGCfMjhIAQBAAAAwY4Q5EP0BAEAAADBjxDkQ/QEAQAAAMGPEORDoaFm3nZCEAAAqMmq8bxbCHK+aluEIB/yDIfz04V9AQAAgprdbpck5fNlCH6SnZ0tSSc8w6XDF8XA4JwgAABQkzkcDkVFRWnfvn0KDQ312bTIqJ7cbrfy8/OVm5t7wm3BsixlZ2dr7969qlWrljdwVxYhyIcIQQAAoCaz2WxKTk7Wpk2btGXLlkCXgwCzLEs5OTmKjIyUzWbzyT5r1aqlJB9ckJMQ5ENMjAAAAGq6sLAwtWrViiFxkNPp1Pfff68+ffr45ALNoaGhJ9wD5EEI8iF6ggAAAKSQkBBFREQEugwEmN1uV0FBgSIiInwSgnyJgZo+xOxwAAAAQPAjBPkQPUEAAABA8CME+RAhCAAAAAh+hCAfYmIEAAAAIPgRgnyIniAAAAAg+BGCfIieIAAAACD4EYJ8iJ4gAAAAIPgRgnyIEAQAAAAEP0KQD3lCEBdIBgAAAIIXIciHuFgqAAAAEPwIQT7ExAgAAABA8CME+RDnBAEAAADBjxDkQ4QgAAAAIPgRgnyIEAQAAAAEP0KQDxGCAAAAgOBHCPIhh4PZ4QAAAIBgRwjyIXqCAAAAgOBHCPIhQhAAAAAQ/AhBPsR1ggAAAIDgRwjyIXqCAAAAgOBHCPIhQhAAAAAQ/AhBPuQJQfn5AS4EAAAAwFERgnyIniAAAAAg+BGCfMhznSCXyywAAAAAgg8hyIc8PUESvUEAAABAsCIE+RAhCAAAAAh+hCAfstst2WyWJEIQAAAAEKwIQT5ks0nh4WadEAQAAAAEJ0KQjxGCAAAAgOBGCPIxQhAAAAAQ3AhBPkYIAgAAAIIbIcjHCEEAAABAcCME+VhoqLklBAEAAADBiRDkY/QEAQAAAMGNEORj4eHmOkH5+QEuBAAAAECZAhqCJk6cKJvNVmJp27ZtIEs6YfQEAQAAAMHNEegCOnTooG+++cZ73+EIeEknhBAEAAAABLeAJw6Hw6GkpKRAl+EzYWHmlhAEAAAABKeAh6D169crJSVFERER6tmzpx599FE1bty4zG3z8vKUVyxdpKenS5KcTqecTmeV1Hs0nuOHhbklhSg72yWn0x3QmlA9eNpOoNswqhfaDSqDdoPKou2gMqq63VTkODbLsiw/1nJMs2fPVmZmptq0aaNdu3Zp0qRJ2rFjh1atWqXY2NhS20+cOFGTJk0q9fi0adMUFRVVFSUf17PPnqoFCxrpiitW6fzz/wp0OQAAAECNkJ2drX/+8586fPiw4uLijrltQEPQkdLS0tSkSRM988wzuuqqq0o9X1ZPUKNGjbR///7jvlF/czqdSk1N1aefDtXbbzv04IMu3XEHPUE4Pk/bGTBggEI9F5oCjoN2g8qg3aCyaDuojKpuN+np6apbt265QlDAh8MVV6tWLbVu3VobNmwo8/nw8HCFe2YeKCY0NDRo/kNGRtokSQUFdoWG2gNcDaqTYGrHqD5oN6gM2g0qi7aDyqiqdlORYwTVdYIyMzP1119/KTk5OdClVBqzwwEAAADBLaAh6Pbbb9eCBQu0efNm/fjjjxoxYoTsdrtGjhwZyLJOCLPDAQAAAMEtoMPhtm/frpEjR+rAgQNKTEzUGWecocWLFysxMTGQZZ0QeoIAAACA4BbQEPTBBx8E8vB+QU8QAAAAENyC6pygkwE9QQAAAEBwIwT5GCEIAAAACG6EIB8LDzeXXcrPD3AhAAAAAMpECPIxzgkCAAAAghshyMcYDgcAAAAEN0KQjxGCAAAAgOBGCPIxQhAAAAAQ3AhBPkYIAgAAAIIbIcjHCEEAAABAcCME+RghCAAAAAhuhCAfCwsz1wkiBAEAAADBiRDkY/QEAQAAAMGNEORjhCAAAAAguBGCfCwszNwSggAAAIDgRAjyMU9PkNstFRQEthYAAAAApRGCfMwTgiQpPz9wdQAAAAAoGyHIx4qHIIbEAQAAAMGHEORjDodks5l1QhAAAAAQfAhBPmazMUMcAAAAEMwIQX5ACAIAAACCFyHIDwhBAAAAQPAiBPkBIQgAAAAIXoQgPyAEAQAAAMGLEOQHhCAAAAAgeBGC/IAQBAAAAAQvQpAfEIIAAACA4EUI8oOwMHNLCAIAAACCDyHID+gJAgAAAIIXIcgPPCEoPz+wdQAAAAAojRDkB/QEAQAAAMGLEOQHhCAAAAAgeBGC/IAQBAAAAAQvQpAfEIIAAACA4EUI8gNCEAAAABC8CEF+QAgCAAAAghchyA8IQQAAAEDwIgT5ASEIAAAACF6EID8gBAEAAADBixDkB4QgAAAAIHgRgvyAEAQAAAAEL0KQH4SFmVtCEAAAABB8CEF+4OkJys8PbB0AAAAASiME+QHD4QAAAIDgRQjyA0IQAAAAELwIQX5ACAIAAACCFyHIDwhBAAAAQPAiBPkBIQgAAAAIXoQgPyAEAQAAAMGLEOQHhCAAAAAgeBGC/IAQBAAAAAQvQpAfEIIAAACA4EUI8gNPCHK7pYKCwNYCAAAAoCRCkB94QpBEbxAAAAAQbAhBfhAWVrROCAIAAACCCyHIDxwOyWYz6/n5ga0FAAAAQEmEID+w2ZgcAQAAAAhWhCA/IQQBAAAAwYkQ5CeEIAAAACA4EYL8hBAEAAAABCdCkJ8QggAAAIDgRAjyE0IQAAAAEJwIQX5CCAIAAACCEyHITwhBAAAAQHAiBPkJIQgAAAAIToQgPyEEAQAAAMGJEOQnhCAAAAAgOBGC/IQQBAAAAASnoAlBjz32mGw2m8aPHx/oUnwiLMzc5ucHtg4AAAAAJQVFCFq6dKmmTJmizp07B7oUn6EnCAAAAAhOAQ9BmZmZGjVqlF599VXVrl070OX4DCEIAAAACE6OQBcwduxYDR06VP3799dDDz10zG3z8vKUVyxVpKenS5KcTqecTqdf6zwez/E9t6GhIZLsys52yel0B7AyBLsj2w5QHrQbVAbtBpVF20FlVHW7qchxAhqCPvjgAy1btkxLly4t1/aPPvqoJk2aVOrxuXPnKioqytflVUpqaqokafv29pJaae3aTZo164/AFoVqwdN2gIqg3aAyaDeoLNoOKqOq2k12dna5tw1YCNq2bZtuvvlmpaamKiIiolyvueuuu3Trrbd676enp6tRo0Y699xzFRcX569Sy8XpdCo1NVUDBgxQaGioli41Iw1TUpppyJAmAa0Nwe3ItgOUB+0GlUG7QWXRdlAZVd1uPKPEyiNgIejXX3/V3r17deqpp3ofc7lc+v777/Xiiy8qLy9Pdru9xGvCw8MV7jnZppjQ0NCg+Q/pqcXTMeV02hUaaj/2iwAFVztG9UG7QWXQblBZtB1URlW1m4ocI2AhqF+/flq5cmWJx6644gq1bdtWd9xxR6kAVN0wMQIAAAAQnAIWgmJjY9WxY8cSj0VHRyshIaHU49URIQgAAAAITgGfIvtkRQgCAAAAglPAp8gubv78+YEuwWcIQQAAAEBwoifITwhBAAAAQHAiBPkJIQgAAAAIToQgPwkLM7f5+YGtAwAAAEBJhCA/oScIAAAACE6EID8hBAEAAADBiRDkJ4QgAAAAIDgRgvyEEAQAAAAEJ0KQnxCCAAAAgOBECPITQhAAAAAQnAhBfkIIAgAAAIITIchPPCHI7ZYKCgJbCwAAAIAihCA/8YQgid4gAAAAIJgQgvyEEAQAAAAEJ0KQnzgcUkjhp0sIAgAAAIIHIciPmBwBAAAACD6EID/yhKD8/MDWAQAAAKCIoyIbp6WlacaMGfrhhx+0ZcsWZWdnKzExUV27dtXAgQPVq1cvf9VZLYWFmVt6ggAAAIDgUa6eoJ07d+rqq69WcnKyHnroIeXk5OiUU05Rv3791LBhQ82bN08DBgxQ+/bt9eGHH/q75mqD4XAAAABA8ClXT1DXrl01evRo/frrr2rfvn2Z2+Tk5GjmzJl67rnntG3bNt1+++0+LbQ6IgQBAAAAwadcIWj16tVKSEg45jaRkZEaOXKkRo4cqQMHDvikuOqOEAQAAAAEn3INhzteADrR7U9WhCAAAAAg+JR7drgbbrhBmZmZ3vvvv/++srKyvPfT0tI0ZMgQ31ZXzRGCAAAAgOBT7hA0ZcoUZWdne+//+9//1p49e7z38/LyNGfOHN9WV80RggAAAIDgU+4QZFnWMe+jNEIQAAAAEHy4WKofEYIAAACA4EMI8iNCEAAAABB8yjVFtseECRMUFRUlScrPz9fDDz+s+Ph4SSpxvhAMQhAAAAAQfModgvr06aO1a9d67/fq1UsbN24stQ2KEIIAAACA4FPuEDR//nw/lnFy8oSg/PzA1gEAAACgyAmfE1RQUFDi+kEoEhZmbukJAgAAAIJHuUPQF198oTfffLPEYw8//LBiYmJUq1YtnXvuuTp06JCv66vWGA4HAAAABJ9yh6BnnnlGWVlZ3vs//vijJkyYoPvuu08fffSRtm3bpgcffNAvRVZXhCAAAAAg+JQ7BP3xxx/q1auX9/7HH3+sAQMG6J577tEFF1ygp59+Wl988YVfiqyuCEEAAABA8Cl3CMrIyFBCQoL3/sKFC9WvXz/v/Q4dOmjnzp2+ra6aIwQBAAAAwafcIahBgwZas2aNJCkzM1MrVqwo0TN04MAB7zWEYBCCAAAAgOBT7hB08cUXa/z48XrnnXd0zTXXKCkpSX/729+8z//yyy9q06aNX4qsrghBAAAAQPAp93WCJkyYoB07dmjcuHFKSkrSu+++K7vd7n3+/fff17Bhw/xSZHVFCAIAAACCT7lDUGRkpN5+++2jPj9v3jyfFHQyIQQBAAAAweeEL5aKoyMEAQAAAMGn3D1B55xzTrm2++677ypdzMmGEAQAAAAEn3KHoPnz56tJkyYaOnSoQkND/VnTSYMQBAAAAASfcoegxx9/XFOnTtX06dM1atQoXXnllerYsaM/a6v2CEEAAABA8Cn3OUH/+c9/tHr1as2cOVMZGRnq3bu3TjvtNL388stKT0/3Z43VlicE5ecHtg4AAAAARSo8MULPnj316quvateuXRo7dqzeeOMNpaSkEITKEBZmbukJAgAAAIJHpWeHW7ZsmRYsWKA1a9aoY8eOnCdUBobDAQAAAMGnQiFo586deuSRR9S6dWtddNFFqlOnjn7++WctXrxYkZGR/qqx2iIEAQAAAMGn3BMjDBkyRPPmzdO5556rJ598UkOHDpXDUe6X10iEIAAAACD4lDvFfP3110pOTtbWrVs1adIkTZo0qcztli1b5rPiqjtPCHK7pYICicwIAAAABF65v5bff//9/qzjpOQJQZLpDSIEAQAAAIFHCPKjI0NQdHTgagEAAABgVHp2OByfwyGFFH7CnBcEAAAABIdyhaBBgwZp8eLFx90uIyNDjz/+uP7v//7vhAs7WTA5AgAAABBcyjUc7uKLL9aFF16o+Ph4DRs2TN27d1dKSooiIiJ06NAhrV69WgsXLtSsWbM0dOhQPfnkk/6uu9oID5dycghBAAAAQLAoVwi66qqrdNlll2n69On68MMP9corr+jw4cOSJJvNpvbt22vgwIFaunSp2rVr59eCqxt6ggAAAIDgUu6JEcLDw3XZZZfpsssukyQdPnxYOTk5SkhIUGhoqN8KrO4IQQAAAEBwqfSkzfHx8YqPj/dlLSclTwjKzw9sHQAAAAAMZofzs7Awc0tPEAAAABAcCEF+xnA4AAAAILgQgvyMEAQAAAAEF0KQnxGCAAAAgOBS4RC0bds2bd++3Xt/yZIlGj9+vF555RWfFnayIAQBAAAAwaXCIeif//yn5s2bJ0navXu3BgwYoCVLluiee+7RAw884PMCqztCEAAAABBcKhyCVq1apdNOO02S9NFHH6ljx4768ccf9d577+nNN9/0dX3VHiEIAAAACC4VDkFOp1Phhd/sv/nmG5133nmSpLZt22rXrl2+re4kQAgCAAAAgkuFQ1CHDh308ssv64cfflBqaqoGDRokSdq5c6cSEhJ8XmB1RwgCAAAAgkuFQ9Djjz+uKVOmqG/fvho5cqS6dOkiSfr888+9w+RQhBAEAAAABBdHRV/Qt29f7d+/X+np6apdu7b38WuvvVZRUVEV2tfkyZM1efJkbd68WZLpZZowYYIGDx5c0bKCFiEIAAAACC4V7gnKyclRXl6eNwBt2bJFzz33nNauXat69epVaF8NGzbUY489pl9//VW//PKLzjnnHJ1//vn6448/KlpW0CIEAQAAAMGlwiHo/PPP19tvvy1JSktL0+mnn66nn35aw4cP1+TJkyu0r2HDhmnIkCFq1aqVWrdurYcfflgxMTFavHhxRcsKWp4QlJ8f2DoAAAAAGBUeDrds2TI9++yzkqSPP/5Y9evX12+//aZPPvlEEyZM0PXXX1+pQlwul6ZPn66srCz17NmzzG3y8vKUV6xLJT09XZKZsc7pdFbquL7iOf6RdTgcIZLsyslxy+l0BaAyBLujtR3gWGg3qAzaDSqLtoPKqOp2U5HjVDgEZWdnKzY2VpI0d+5cXXDBBQoJCdHf/vY3bdmypaK708qVK9WzZ0/l5uYqJiZGM2bMUPv27cvc9tFHH9WkSZNKPT537twKn4/kL6mpqSXu//VXC0kdtXHjDs2atSwwRaFaOLLtAOVBu0Fl0G5QWbQdVEZVtZvs7Oxyb1vhENSyZUvNnDlTI0aM0Jw5c3TLLbdIkvbu3au4uLiK7k5t2rTR8uXLdfjwYX388ccaPXq0FixYUGYQuuuuu3Trrbd676enp6tRo0Y699xzK3VsX3I6nUpNTdWAAQMUGhrqfXzzZjPisG7dBhoyJClQ5SGIHa3tAMdCu0Fl0G5QWbQdVEZVtxvPKLHyqHAImjBhgv75z3/qlltu0TnnnOMdujZ37lx17dq1ortTWFiYWrZsKUnq1q2bli5dqv/973+aMmVKqW3Dw8O9F2otLjQ0NGj+Qx5Zi6eDyukMUWhohU/BQg0STO0Y1QftBpVBu0Fl0XZQGVXVbipyjAqHoIsuukhnnHGGdu3a5b1GkCT169dPI0aMqOjuSnG73SXO+6numB0OAAAACC4VDkGSlJSUpKSkJG3fvl2Smeq6MhdKveuuuzR48GA1btxYGRkZmjZtmubPn685c+ZUpqygRAgCAAAAgkuFx2e53W498MADio+PV5MmTdSkSRPVqlVLDz74oNxud4X2tXfvXl1++eVq06aN+vXrp6VLl2rOnDkaMGBARcsKWoQgAAAAILhUuCfonnvu0euvv67HHntMvXv3liQtXLhQEydOVG5urh5++OFy7+v111+v6OGrHUIQAAAAEFwqHILeeustvfbaazrvvPO8j3Xu3FkNGjTQDTfcUKEQVBMQggAAAIDgUuHhcAcPHlTbtm1LPd62bVsdPHjQJ0WdTAhBAAAAQHCpcAjq0qWLXnzxxVKPv/jiiyVmi4NBCAIAAACCS4WHwz3xxBMaOnSovvnmG+81gn766Sdt27ZNs2bN8nmB1R0hCAAAAAguFe4JOuuss7Ru3TqNGDFCaWlpSktL0wUXXKC1a9fqzDPP9EeN1ZonBOXnB7YOAAAAAEalrhOUkpJSagKE7du369prr9Urr7zik8JOFvQEAQAAAMGlwj1BR3PgwIEaMeV1RYWFmVtCEAAAABAcfBaCUDZPT5DbLRUUBLYWAAAAAIQgv/OEIIneIAAAACAYEIL8jBAEAAAABJdyT4xwwQUXHPP5tLS0E63lpORwSCEhZjgcIQgAAAAIvHKHoPj4+OM+f/nll59wQSej8HApJ4cQBAAAAASDcoegqVOn+rOOkxohCAAAAAgenBNUBbhWEAAAABA8CEFVgBAEAAAABA9CUBUgBAEAAADBgxBUBQhBAAAAQPAgBFUBTwjKzw9sHQAAAAAIQVWCniAAAAAgeBCCqgAhCAAAAAgehKAqEBZmbglBAAAAQOARgqoAPUEAAABA8CAEVQFCEAAAABA8CEFVgBAEAAAABA9CUBUgBAEAAADBgxBUBQhBAAAAQPAgBFWBiAhzm5MT2DoAAAAAEIKqREqKud26NbB1AAAAACAEVYnWrc3tunWBrQMAAAAAIahKFA9BlhXYWgAAAICajhBUBZo1k+x2KStL2rUr0NUAAAAANRshqAqEhZkgJDEkDgAAAAg0QlAV4bwgAAAAIDgQgqoIIQgAAAAIDoSgKkIIAgAAAIIDIaiKEIIAAACA4EAIqiKeEPTXX1JBQWBrAQAAAGoyQlAVadBAiow0AWjz5kBXAwAAANRchKAqEhIitWpl1hkSBwAAAAQOIagKcV4QAAAAEHiEoCpECAIAAAACjxBUhQhBAAAAQOARgqqQJwStXRvYOgAAAICajBBUhTwhaPt2KSsrsLUAAAAANRUhqAolJEh16pj1DRsCWwsAAABQUxGCqhjnBQEAAACBRQiqYoQgAAAAILAIQVWMEAQAAAAEFiGoihGCAAAAgMAiBFUxQhAAAAAQWISgKtaypbk9eFA6cCCwtQAAAAA1ESGoikVHSw0bmnV6gwAAAICqRwgKgDZtzC0hCAAAAKh6hKAA4LwgAAAAIHAIQQFACAIAAAAChxAUAIQgAAAAIHAIQQHgCUHr10tud2BrAQAAAGoaQlAANG0qORxSTo60Y0egqwEAAABqFkJQADgcUosWZp0hcQAAAEDVIgQFCOcFAQAAAIFBCAoQQhAAAAAQGISgACEEAQAAAIFBCAoQQhAAAAAQGISgAPGEoE2bpPz8wNYCAAAA1CSEoABJTpaioyWXywQhAAAAAFWDEBQgNhtD4gAAAIBACGgIevTRR9WjRw/FxsaqXr16Gj58uNauXRvIkqoUIQgAAACoegENQQsWLNDYsWO1ePFipaamyul06txzz1VWVlYgy6oyhCAAAACg6jkCefCvv/66xP0333xT9erV06+//qo+ffoEqKqqQwgCAAAAql5AQ9CRDh8+LEmqU6dOmc/n5eUpLy/Pez89PV2S5HQ65XQ6/V/gMXiOX5E6mje3SXJo3TpLTmeBnypDsKtM2wFoN6gM2g0qi7aDyqjqdlOR49gsy7L8WEu5ud1unXfeeUpLS9PChQvL3GbixImaNGlSqcenTZumqKgof5foc5mZobrssiGSpPff/1KRka4AVwQAAABUT9nZ2frnP/+pw4cPKy4u7pjbBk0Iuv766zV79mwtXLhQDRs2LHObsnqCGjVqpP379x/3jfqb0+lUamqqBgwYoNDQ0HK/rkEDh/bts+nnn53q2tWPBSJoVbbtoGaj3aAyaDeoLNoOKqOq2016errq1q1brhAUFMPhbrzxRn355Zf6/vvvjxqAJCk8PFzh4eGlHg8NDQ2a/5AVraV1a2nfPmnjxlCddpofC0PQC6Z2jOqDdoPKoN2gsmg7qIyqajcVOUZAZ4ezLEs33nijZsyYoe+++07NmjULZDkBweQIAAAAQNUKaE/Q2LFjNW3aNH322WeKjY3V7t27JUnx8fGKjIwMZGlVxhOCVq0KbB0AAABATRHQnqDJkyfr8OHD6tu3r5KTk73Lhx9+GMiyqtQZZ5jbb7+VXMyLAAAAAPhdQHuCgmROhoD629+kWrWkgwelpUvNfQAAAAD+E9CeIEgOhzRggFk/4tqxAAAAAPyAEBQEBg0yt7NnB7YOAAAAoCYgBAUBTwhautRMlw0AAADAfwhBQSAlRerSRbIsae7cQFcDAAAAnNwIQUFi8GBzy5A4AAAAwL8IQUHCE4LmzJHc7sDWAgAAAJzMCEFBomdPKS5O2r9f+uWXQFcDAAAAnLwIQUEiNFTq39+sMyQOAAAA8B9CUBDxDInjekEAAACA/xCCgohnquyff5YOHAhsLQAAAMDJihAURBo2lDp1YqpsAAAAwJ8IQUGGqbIBAAAA/yIE+UjI73fqnOwbZdvx2Qntp/h5QUyVDQAAAPgeIchHbDm7FWttly1j3Qntp1cvKTZW2rdPWrbMR8UBAAAA8CIE+YgV3dSsZG0+of2EhUn9+pl1hsQBAAAAvkcI8hErprkkyXaCIUhiqmwAAADAnwhBvlLYE2TL2nTCu/KEoMWLpYMHT3h3AAAAAIohBPlI0XC4LZLbdUL7atRI6tDBTIyQmnritQEAAAAoQgjylcgGcsshm+WUcnae8O6YKhsAAADwD0KQr9jsyrYlmnUfDoljqmwAAADAtwhBPpRtq2dWMk88BPXuLUVHS3v2SMuXn/DuAAAAABQiBPlQdkh9s5K58YT3FR7OVNkAAACAPxCCfCjb5glBJ94TJBUNiXvzTSk72ye7BAAAAGo8QpAPZXl6gnxwTpAkXXqplJIibdgg3XmnT3YJAAAA1HiEIB/ydU9QrVrSG2+Y9RdeYLpsAAAAwBcIQT7kPScoZ4fkyvXJPgcOlMaONetXXCEdOuST3QIAAAA1FiHIh/IVK8sRY+5kbfHZfp94QmrdWtqxoygQAQAAAKgcQpAv2WxSdDOz7qMhcZIUFSW9845kt0vvvy998IHPdg0AAADUOIQgH7Oim5oVH02O4HHaadK995r16683vUIAAAAAKo4Q5GOWtyfoxK8VdKR77pG6d5fS0qQrr5Qsy+eHAAAAAE56hCBf8/QE+XA4nEdoqBkWFxEhzZ0rvfSSzw8BAAAAnPQIQT5m+TEESVLbttKTT5r1//xHWrvWL4cBAAAATlqEIB/zDofz8TlBxd1wgzRggJSTI40ZI7ndfjsUAAAAcNIhBPmapyco/5CUn+aXQ4SEmIuoxsZKixdL773nl8MAAAAAJyVCkK85oqWIembdT0PiJKlhQzNRgiTdeaeUmem3QwEAAAAnFUKQP1TBkDhJuvlmqVkzaedOc0FVAAAAAMdHCPKHmObm1g/TZBcXESE99ZRZf/JJacsWvx4OAAAAOCkQgvwhxnOtIP/2BEnSiBFS375Sbq50xx1+PxwAAABQ7RGC/CG66kKQzSY9+6y5/fBDadEivx8SAAAAqNYIQf4QUzXnBHmccop09dVm/eabmTIbAAAAOBZCkD94zwnaJFlVk0gefNBMmf3rr9Lbb1fJIQEAAIBqiRDkD1GNJJtdcudJObur5JD160v33WfW77qLKbMBAACAoyEE+UOIwwQhqcqGxEnSuHFSixbS7t3So49W2WEBAACAaoUQ5C9VOEOcR3h40ZTZTz8tbaq6QwMAAADVBiHIX6roWkFHOv986ZxzpLw8afx4yeWq0sMDAAAAQY8Q5C/RVTtDnIdnyuyQEOnzz6UhQ6SDB6u0BAAAACCoEYL8JQDD4Tw6dzbXDIqKkubOlXr0kFaurPIyAAAAgKBECPKXKrxgalkuukj66SepWTNp40apZ0/p448DUgoAAAAQVAhB/uI5Jyh7m+TKD0gJnTtLS5dKAwZIWVnSxRdLd9/NeUIAAACo2QhB/hJRT7JHSbKk7K0BKyMhQZo1S7r9dnP/0UelYcOkQ4cCVhIAAAAQUIQgf7HZpJimZj1AQ+I8HA7pySeladOkyEhp9mzp9NOl9esDWhYAAAAQEIQgfwrQDHFHM3Kk9OOPUpMmJgD17CktWhToqgAAAICqRQjypwBdK+hYTjlF+vln6bTTpAMHpH79zExyAAAAQE1BCPKnAE6TfSz160vz5knDh5uLql56qfT445JlBboyAAAAwP8IQf4U4GmyjyUqykyZPX68uX/nndJ110kFBQEtCwAAAPA7QpA/xQTXOUFHstulZ5+Vnn9eCgmRXnnFzByXkRHoygAAAAD/IQT5kycE5e2XnMGbLG66SZoxw/QOff211Ls3EyYAAADg5EUI8qfQOCk8wawH4ZC44s47T1qwwJwvtHKldMYZ5pyhNWsCXRkAAADgW4QgfwuyabKPpXt36bffpGuuMcPjPvtM6tjR3N+5M9DVAQAAAL5BCPK3IJ0h7miSk825QatWmZ4gt1t67TWpZUvpnnukw4cDXSEAAABwYghB/haE1woqj3btzHlCixaZc4RycqRHHpFatDAhye0OdIUAAABA5RCC/C2Ip8kuj169pB9+MEPj2rUzF1j997+lv/1N+uWXQFcHAAAAVBwhyN+CfJrs8rDZzMQJv/8u/e9/UlyctHSpdNpp0vXXSwcPBrpCAAAAoPwIQf5WvCfIsgJbywlyOKRx46Q//5Quu8y8nZdfltq0kd54gyFyAAAAqB4cgS7gpBfdRJJNcmVLuXulyPqBruiEJSdL77wjXX21NHas9Mcf0lVXmUB01llSgwZSSoq59ayHhQW6agAAAMAgBPmbPUyKaihlbzND4k6CEORx1llmSu3nn5cmTjRD5JYuLXvbpCTTe/Tf/0qJiVVaJgAAAFBCQIfDff/99xo2bJhSUlJks9k0c+bMQJbjP9VsmuyKCA2VbrtNWrtWevZZ6ZZbpEsuMTPKNW1a1AO0e7f01FNSs2bSnXdK+/cHtGwAAADUYAENQVlZWerSpYv+7//+L5Bl+J/nvKD0tYGtw49SUqTx46VnnpE+/FBauFDatEnKzZX27pU+/9xcjDUrS3r8cROG7rmHSRUAAABQ9QIaggYPHqyHHnpII0aMCGQZ/le3p7ndMEVyZga2lipms5nhb8OGSUuWmDDUtauUmWmuO9S0qXTffWYa7jVrpH37JJcr0FUDAADgZFatzgnKy8tTXl6e9356erokyel0yul0Bqosbw3Fb0tofJkcq5+QLWujXH88IXeH+6q4uuAxaJA0cKD0+ec2PfigXb//btNDD0kPPVS0jc1mqU4dqW5dqW5dS717W7rqKreaNQtc3f50zLYDHAXtBpVBu0Fl0XZQGVXdbipyHJtlBce8zTabTTNmzNDw4cOPus3EiRM1adKkUo9PmzZNUVFRfqzuxKUULFSPvKdUoAh9EzlZeSG1A11SwLnd0uLFyZo9u5kOHIjU4cNhysoqexo5m83SKafs1cCBm9Wjxx7Z7UHRbAEAABAksrOz9c9//lOHDx9WXFzcMbetViGorJ6gRo0aaf/+/cd9o/7mdDqVmpqqAQMGKDQ0tPQGliX7d2co5OBSuZpfI3e3k/w8qEpyOqUDB8zECfv327Rtm/TBByFKTS0auZmSYmnMGLeuvNKtxo0DWKyPHLftAGWg3aAyaDeoLNoOKqOq2016errq1q1brhBUrYbDhYeHKzw8vNTjoaGhQfMf8pi1nPq09E0f2Te9IXu7W6T4dlVbXDUQGipFRUmNGhU9duWV0l9/Sa++ai7KunOnTY88Ytdjj9nVvbu5WGvr1kVLq1ZSdHTg3kNlBVM7RvVBu0Fl0G5QWbQdVEZVtZuKHKNahaBqr96ZUsPzpe2fScvvlM76LNAVVRstWkiPPSY98IA0Y4Y0ZYo0b56ZbGHJktLbN2ggtW8vnXKKmYjhlFNMQLLbq7pyAAAABJuAhqDMzExt2LDBe3/Tpk1avny56tSpo8YnwzinsnR5TNrxpbTjc2nv91K9PoGuqFoJC5P+8Q+zbNxoLta6bp1Z1q41twcOSDt2mCU1tei1UVFS584mELVsaXqd7HazOBxFt4mJUv/+Zh0AAAAnn4B+zfvll1909tlne+/feuutkqTRo0frzTffDFBVfhbfVmpxjbThZWnZ7dLAxZItoDOVV1vNm5vlSAcOmDC0apUJScuXSytWSNnZ0uLFZjmexo2lceOkq6+W4uN9XjoAAAACKKAhqG/fvgqSeRmqVqeJ0uZ3pINLpa3TpSb/CHRFJ5WEBKlnT7N4uFzShg0mFP32m7R9u3nM5ZIKCkqu//abtHWrdPvt0sSJJgiNG6eTdopuAACAmoYBP4EQWV9q919p5f3S8rukhsMle+kJH+A7druZQKFNG+nSS4+9bW6u9N570jPPSKtXS889Jz3/vDRihHTNNVJEhJSRYS74mplZtJ6TI8XGSrVrS7VqlbxNSDALAAAAAo8QFCjtbjND4rI2SetfktreEuiKUCgiQrrqKjMr3dy5JgzNnSt98olZKqtLF+lf/5L++U8pOdl39QIAAKBiCEGB4oiWOj0gLblGWvWg1HyMFMYFVIOJzSYNHGiWVaukZ5+VvvvOhKSYGLPExhate3qI0tKkQ4dK3qanm/OSVqyQ/vtfqV8/E4hGjJDKmPUdAAAAfkQICqTmY6S1z0qHV0szG0kxzaWYllJsCymmhRTb0txGN2HyhADr2FF6/fXKv/7gQemjj6R335UWLTKz1qWmmhnrzj/frujoZsrJsalhQ9NLlJxsnjsWl8sEtRCaBgAAQIUQggIpxCH1mCx9P1zKPySlrTTLkSKTpZShUoPzpKR+kuM4344RdOrUka67ziwbN5ow9M47ZrKG998PkdRZr71W8jWxsSYMORxSXp45V6n44nKZc50SEqS6dUsvUVGlJ33w3CYmSmPGmOspAQAA1DSEoECr10casUvK2ixl/CVlFi4Zf0mZG6TMjVLOLumv18xij5Dq95caDpNS/i5FpQT6HaCCmjeXJkyQ7rvPXOj1o49c+umnPZKStGdPiHbtMpMsZGSY5VhcLmnvXrNU1MSJ0iWXSOPHSz16VOKNAAAAVFOEoGBgD5fi2pjlSK48ac98aeeX0o4vpKwtZn3nl+b5qMZmuFyZS1NmnQtiNpt0+unSqae6NWvWUg0ZMkShoSGyLHMO0e7d0q5dkmWZ84YiIkou4eGmh2j//qLlwAFzu2+fCVLFLwLruTCs3S79+KP0/ffStGlm6dVLuuUWafjwkheJdblMz9Xq1WbZutUcNzq69OI5RyouruQSHm7eKwAAQLAgBAU7e7iUMtAs3Z6XDq8yYWj7F9KBn6XsrWbZ90Pp19rsUmxrKb6DVKujFN/R3Ma0MEPxEJRsNnOB1vh4M6X38aRUsjNw2TIz/fcHH5hQ9OOPUpMm0kUXSTt2mNCzdq0JWifC4TBhqF49M7wvKan0bePGZomIOLFjAQAAlAffhKsTm02q1cksHe6WcvdLGetM71DxJXuruS3IlNLXmGXbx0X7CQmXanU25xcl9ZPq9pYckYF7XwiIU0+V3n5beuwxafJk6eWXpS1bpKefLrldRITUrp3Uvr0Zyud0SllZpRfPNZPS00sO5SsoMBNDHDwo/fnnsWtKSpKaNi25nHKK1K1byR4qAACAE8HXiuosoq5ZEnuVfs6ypJydUtoq03t0eFXh+h+SK0c6uNQsqx8zoSixl1S/n5TU3wSkgkwpP01ypknOw2Y9P01yppvXu3Ild6659SzufCkktHAJM4stVLKHSfYoqX5fKfEMZroLMikp0oMPSnffbYbGLV0qtWhhQk+7dqZ3yG6v+H7dbhOM0tOlw4elPXvMED/PMD/P7a5dZphdZmbR84sXl9xXXJx09tlS//5mevG2bRliBwAAKo8QdLKy2aSoBmZJGVj0uOU2ky3s+1Ha8620+1spZ4e0Z55Zfr/XfzWtlBTZQGp8sdTkUinhNL7JBpHISHOR2Kuu8s3+QkKKzgtq2FDq0OHo21qW6SnavLnksnGj9NNP5npLn31mFskEt/79TUizrJKL221uj8XtNsP8PEt+ftF6QYEUFla0hIcXrTscpXu8PLd5eeaaUjfeaEIaAAAIXoSgmsYWYq4/FNtSan65+baYvrYoEO2ZZ3p/JMkRK4XVMkuo5zZOskeaWersEVJIRLH1UMldIFlOyZVveoY863l7pR1fmsC19jmzRDeVGl8iNfmHFNvK7MPmIBjVQDabmeo7IcEMfSvO5ZJ++0365huzLFwo7dxphvIFmw0bpP/7P+ncc6WbbpKGDOE6TgAABCNCUE1ns0nxbc3SeqzkdkkF6SYA+XryBFeetGuOtOVDacdnZlrwNU+YxVtPSLFgVRi2QuOl8LrFloSi9Yh65jpKkcmm5uMFqIJsKW+fpBApqmHFA5dlEdKqmN0ude9uljvvNLPe/fij9O23Ziid54KxxW89y9HYbKaHx7N4enzCw01vj9NZsocoP98sBQVmJjzPLHjFb7OzzQV1P/9cmjvXLC1amJ6hK64wE11URFpa0TlUTZpI9esTqAAA8BVCEEoKsUthtf2zb3u41PA8sxRkSztnSVs+MLeuHLON5ZZc2Wap8P6jigJRZLLpVcrbX3LxHEeSHDFSXDspvn3JJbyuGTKYsb5w2VC0nrvH7NceYd5P8Z4we5QU3ViKaS7FNJOim5v16CbmvCgPt8ucc1WQKTkzpLzDCrWOc0EgeEVGmvOC+vULdCWlDRtmhvC99JL02mvSX3+ZqcfvvVfq2rVoRjzPkpRkln37pDVrTOhZs8Yse/aU3HdYmJlBr0kTszRsGKK9e5tq/36boqKKpk333MbHm4klYmKOX3denpkJ8I8/zDTrf/+7eW15WJb03XfSjBlSy5bSiBGmPgAAghkhCIHhiJIaX2QWy216iY6caMGVY5b8tMIQc8Dc5h8oCjW5e8zFZJ3pJjh5LjZ7LCFh5pgFmUUTRFSEVVAUYo5U5r5sJpRZBZIzs1TAC5U0RJL19UNmgoq6vaS6PaX4dkwiUQ01by499ZQ0aZL07rvS88+b6cYXLqz4vho0ML0/O3aYnqgNG8xi2CV1Oe4+6taVmjUzdTVrZpaYGBO4/vjDLBs2mGGHHuPGSUOHStdfb85zKmtijJwcM5HGc89Jq1YVPX7LLWbmwREjzNK+PZ2nAIDgQwhC4NlCCqfoPoFpuguyTBgqvlguKSLxiKF0dU0PkFUgZfwlpa+WDhdb0v+U3Hlmu5iW5lwl79JSimpk9lsqsOVKBRlmavLMjVLmpsLbjSb05Ows4307pNBYWSHhsuXuli1jrZSxVto41TwfGi/V/ZtUp5sU38lc4ym2dclepSM/g7Q/pLTfpbSV5n3Eti68EG9bcw5WSCWmeUOlREdL//63dO210q+/Sps2Fc2GV3xmvN27pdq1zSQPnqVtW7PExpp9OZ0mCG3ZUrRs2uTW6tV7VLt2feXnhygvT8rNlffWMy2550K6S4+T9ePjzeQVdrv0ww/Sl1+apVkz8z6uvFJKTDTnY730kjRlitmv571econp+Vq40FyDatky6b77pFatTBjq0UNq1MgsSUkM7QMABBYhCCcHR3TRhA/lYQstOheq0QVFj7tdJrSExvqmLssy5yBlbTU9UKGx5tyl0BgzNbnNpgKnU9989YEGdI2VI22pmbnvwBIzNfmuOWbxCAmVYtuYQFSrk5l0whN6Mv+SdIxp0ULCCj+jNlJkigmCbqeZwKL4bYjD7Lv2qVKdrlJU47L/lO92muB48Ffp4C9S+jpznpVnWGFcO4KXzEfnOaepskJDi66b5OF0ujRr1hINGTJEoaFlJ4r0dBO+Nm40t57l8GFzId4OHYqWlJSif+a1a811o6ZONdvfeac0YYLUq5cJOQUFZrsmTcwEEFddJdWqZR7bt8+cFzVjhpSaKq1fLz3xRMm6HA7Ty+UJRZGRZp9Op1mKr9erJ/XuLZ1xhulVOpHw5HKZmfwOHy65pKUVreflSZ06ST17mhoBACcnQhBQXIhdCvFRAJLMt8qIemY5hnxbnKyUIVKT4eYBd4EJN/t/Kgo5aatMb5Pnuk9bPii9o4j65jpPtTqZiSXSC3uXMtab3ipPj9fxbJ9ZtB5WR6rd1QSi6KbmWlMHf5UOrTC9TcdijzC9UHHtpPBEEwJD44qFwTjTM+dMk7J3mNkDs3ea25wdpkcvvK4ZIpjYy1zYN76D/4KV5Taf/dF626qZuDipSxezVESbNtKzz0oPPyx98IHp+fn1V2n+fPP8GWdI48dL559f+iK2iYlFU61nZEizZ0tffWWG3G3danqSCgqKerSOJcyRJ3uIS+++GyXJBC1PIOrd24TCvXvN+VPFl717TS+V5xpVntvMMkawHkvDhtLf/la0eGYuTEsrWjwhKj3dzG7oOWcrIYFhgMBJw+0yF6e3h0uRDU+a3xE1HSEICEYhDqnOqWbxsCwpe1vRBXDTVhX22hSGnlqdjh62LLfpjfKEoty9hRe0LXZhW8/9gkzp0HLp0G/mGPkHzRTqe74tvd/Q+MI6u0lx7U1wKT600JVbuK/llf8snOlmWOHmdwuPGScl/E1K7G0monDlmIk2vLeF6668wt6uAnNbfN2db4YPFmQW3hYunokz7BFmghDPElp4G15Xqt258P22K/8MivmHJbkLJ9IIL32ul+WWsrebSTgyNxROxrHB9O5FJEnNLpMajjA9iFUoKkq6cnS+rvzHLq35dYfWrDioVt3aqFPPFuU6Xy021gyTu+SSoscKCswwwG3bipb8fNPbFRpqqV74GjWL+FqNHHOUHLJAdlue9melaM32llq7s5U27GmpX2a01Acvt9SuQ8lyue0qcDvkctu9S4HLIbcVIqnsFOKZOKJWLXNbfF0yge/336Xt26WPPzZLRUVHFwWiJk2k1q3L7nUrwXJL+YfM/8/cvebSAvZoqe7pZlZMnHzyDkqyqvbf15UfPF/is3eYn7vRzYJr1IArVzrwi7TvB2nvD9L+H83oDEne83yjGpvfQdFNzHp8W/O7obyTS+Ufkg4uM7+34tubCZVO9Dxgyy3l7jPnTIc4zIiTkLDCiZzCCu+HFg7rdxZdxsQqNhrEcksqvPCerGLrhX8k9I4cyS+5LkmNLzyx+qsYIQioLmy2wh+4jaUGQyr42hAppqlZNPA4Gxfjyivs+VlmQlHWFjNhQ53u5od9TPOj/9B2u6SsTYWBaK35gV+QYWbEc6YXrRdkmmAT2cAM04sqdhuRLGVvNUME9y+S9i82r9091yz+4sotOrfsaOyRhT1k3aWE7iaE5h0smpwjc6M57yxzY9G1tzxCwopdXyvM/NI6aq/a7+a9OqKlRhdKzS6X6p9derOCLNNDt3+xdOBnKWd3sSBXpzDEFd46ogvPYysWGj3rzoyiXrmcHebLuKR2ktolSNosaUec+ff3tIM63QvbwvG7PhyOomFwcheYX9b7Fkm7vjZL9vZSr6kbvVNnttmpM9t8f9z9e7gth/JC6qnAnigrrJ5skfVkj66nsLh6ckTXL7yYdEOzhMaVen1mpglDixdLS34u0NrfDyo/K025zghl5MYpJCxWcfF2b3iKiTFDAbdsMb1RWVlmQozVpTpeLXVpsVFDey5Xr/a/qX3SctWJ3KZI216FuvbJJlepWiTJHdNWaY5e2pTZS79t76Wlf7ZRdk6IWrUyAatNG3P+VXlmA/TKTzPDWDPMYqWvlTtzu+xR9cwXO8+XO896eF3fdG9Zlvl/n7dPyt1v1j1fyNzFFstp2nV+mvn5kX/I/F/KP2Qek4p6mj3DcGNbmi953vd4SDq8ptgfZ1abPyaF1zU/ZyKSpajit0lm4h7vF8bCL5C2wq9LzsPm/0f29sKe6x1SzvbCXuvEoj9IHe2PUllbzJdqz5fr9DXm8djWRRPjJPY276syX4idGeYPXtlbTY3Z28379a5vNz97Q+PNOa5RjczvFM96VMPCa/aFSPJcc6Bw3eVStHtX4R/RErxDusvNlW/+ILb/JxMq9v9kapPMvuLamp7++PaFtx3MZ+iZBMnzh4GcPeY272DZX8aLL668wvW8onWroHBUQq3Cn4+1iq6FaI8wNR5YUvTF3sMeJcld+Pthp1kOLC79PmOaF/5c9PyMPNW0+UPLCoePFy6ZG0vvP75DsTbU0fz/8/xc9swoW5BhJllyphX+ntpZ9Psqd7cJOIFgj6x2IchmWce7tnrwSk9PV3x8vA4fPqy4uNK/xKqS0+nUrFmzCsfnhx7/BUAh2k4FuAtML9i+RSYY5R8wX+jtkeYXiCOqaN1e+Bcvm8P8RczmWezmi40juuzF5jBfdDxfuoovObsKf5EtK3t2wBMRElo4vXrhuW0xLc1fBg8ukza9bXqIPKIaydV4pH7fmK3ODfNkP7jEfC7++uUXEmq+MIbGmy/MrtzS24TGmy+B3s8yqvDfpnC9IMvM8Jh/sOjW+5fVYuwRUr2zpORBUvJA8yUo46/CHrL1xXrJ1pv9+IIjtigQhSeauorPSHlkiPXWGlU4vDOuaKinI1aukFhl5MbpUGasDhyO056D0VLmJtULXa7WicsVH5V+zHIOZdXWoZx6yipIVFz4PjWpvbbUNgcy6mjtrjay2SzZQ1xyhBTIHuJSRHiBIiNcCguzFGJ3KMThkMPhkCPMIUdYqByhdh0+tEfx9oNyFOyr2Odkj/BeMNsKiZTTilSuM1LZeVHKyo2Uy23+km/JJslWeCtJNsVHpSshep/CrH3HCf0nyOYwE9lEJJr2cqw/ZFRm31ZB+bePqFc0qU3uXmnfwqIv/ccTWsvMElqro/l55fk55vmZZnOYzzB7mwlWWVvN7dHaqj+EhHrbfNGF1MMLw2O46W3yBMnMv8y5o0f+7LCFmG2KX74iWETUkxLPNEu9M6RaXczvD895vtlbi332m4udm1sB0c3MZ+eZlMknbCbcWW6zT3deYe/OcV7jGQ1iK+xF996a/89mm1CVHkVSuG6PlM4p/cfJqv6OU5FsQAjyEb7IorJoO9WQ5TZ/QT/4S9FyeI354hXTojDMFL9tZn5RHDmjoDvX/HUyvK75K+zRhoNYlvmr6aa3zcWGj/ZFJzLFzCiYcLo5tifM5R0sDHKFtwVZ5heWI6owPBYLkY6YwmttNSjslWtghup4/irtnRDjF/PXzAO/SGkrSv/VtCLi2hWFnnp9CmeLLCfPeVyWq9hSUHRh5OJDyzzrubuL/ppfkS+Njljzb+Z2VvgtFue2hSnN6qSNh7pq2eZTtHJTS63bWl9rNtXT7kN15XSVHKqUELNfPVv9pH5dflSf9j+qY9IShdnLCKKVsONgitbtbq21u9po3a7W2nagkRLj9qlJ3S3epXHCViXX2qWQEN9+XXDbImSLTJQtNLbwi35o4ReqwsUWKjkiZYXWVlp2bW3YUksr19XWLytqa9POWgq1O9U25U+1b7BaHRqtUfuU1YoOL/3HiXRXIx222ivD1k7Zoe3ljmyqlMSDSorbKYdzZ7G/pu80vQye/5dHm2gmrLYJzMX/j0Qmm/2krTz2RDU2u+khSDyj8At2b/PY/sWmt3vfj6Yn90RCQVjtYj07jYoCvmc9PMH8P8jeVhiithatZ+8obN9u83/LcheuW7IslwpyDytUJ1JbHRPu6vY0PV91epifO1mbzeym6avN7eE/TC+ZK8f8MSW8njnn1XOObUQ9KSyh2DCvsr6Yhx8xDMzTq2cvHJGQVqyXMc3cd6abHqnEM0yYrmjPp2eIW/Gfj1mbzHMleoi6mcmHwuuY59wF5o87hwvP/01baf6wlbPbDIN2xBRNquSILfqjS0RyyesjRqaYzybkiO8SbldRIHLlFwVq7/87/w1FJAT5CSEIJwPaDirElSvt+FLuje/o4O6/VLvVQNkTe5nzRqIaBqimfNNDlJ9mhm54z7HyrGebLzphdcwXMO9tghmCUt5zq/zBmVk4rGm7+QKYt6+wV8szrX6CuQ2rXVSnK6/YkM70wi9Uh4sNVSn2uOd+ZLIZPln7FDOk9MgvKZLcbunQITOczjONut1uLkLbooWZSt0cv3BYUfa2Yr2cdmVkObR9h11btzm0c6d06JBLhw8VKD3NqfTDBcpId0ruArmtEG0/1Ey2+NZq0iJWbdsWTc/eoIG5htSvvxYta9ZIjpA8pdTeqZiITEWG5igqPFsxkTlqkJSjhvWzlZSYo7Awt2yecwgk2WyWbLJkWZY2bInVslWJ2n04UfvSE7UvI1HZeVGKjbV5h/FFR5vb4uvbtpkJOXbsKPlZhYebiTH27DETUxiWGtTZofYNVisxdp/W726lP3e1VUZO2d8PQkLM+VqeIYWtWpkp4V0uKTPTUmaGS7lZecrOzFdudr6cefmq2yBBnU6JUteuZhKQsrjd0ppVWVrz02rt37BSIRl/KCs/VjudZ8oZ/zc1bRntPWbTpuZ8uJI7cJoJcfYtMj0NJc5rdGr/vgKtX+vUgUMOuSMaKz6lsRq0aqwm7RsrNL6x72Y3PYL3d9XgQQq1Ff4fKL64cooNQcsrORQtvJ4JPbGtyx8srMKhZ44ov7yfKpN/yNz660L0QS6YQxDnBAFAdWKPkBpfJFfy+Vo0a5aGdB4ie6DDsz3MDNupjkJjpNA25npa5WUPl+yJko7yLbiSQkLMrHIJCWY68KMfP0yqe5qk00o8HCupXStz/lZZLEvat8+pzz//Tpdd1lkREWW3m969zeKRlSWtWBGu1aubKT5eatzYnNNVv37ZF9I9msxMackSM836okXSTz+ZGQSXLTv+a8PCzAx9Z58t9e1r1iMiiurbuVPascOmHTsaaseOhtq7V6qVI3XKNRf2zS28zckxM/r99Zc5tmfa+LmlRvHYZL4iOSRFl1lTw4ZS167m4sCdO5vzwb7/3lxn68CBaEk9CpejczjMlOzDhknnnWf2ZQsJLeotKORySZ99ZmZtPNqFlyMjzQyGp59u6rHZzKQjTqe59Swul2lj9eqVXGrXLmc+sYUUDQP1J1uI3CFRqvaXFKuh4ac6IAQBAFAD2Gzmi25iYm6Fwkt0tLlGVK9eJ3b8mBjpnHPMIpkv46tWmQCTmWmWrKySt/Hx0llnmdATeZRRktHRphenVavy12JZphdp/Xpp3Tpzu369tHmz6WWKjS3qlfIsYWFm299+M9tu326WL74ovf+oKPN59ekjnXmm2afnOOvWFS05OWZ/v/0mPfCA6Yk77zyznH22uW7VG29Izz9vwppkeo4uvdQEp1WrCifvWGJ6xBYuPHpIOh6Hw/RuJSVJyclmKb5et65NmzfHav1683lERJj3FRFhPhtfzJlRUGAC8uefm2XDBrNfh8O8b4ejaD0+3nxGgwdL/fpVcFKQKrRvX9EfOHzJspiG/0QRggAAQJWz2yt3HStfsNnMF/ykJBNSKio9XVqxoijArFxpesbOOssEn27dSg9z69mz5H2324SoefPMF/45c8ywv8mTzRITY+rMyDDbJyRI110n3XCDmWZdki6+uGhf69ZJP/9slrVrTVgICyu92GzSgQPmelqeJS2taPr6XbvMeyrNIemco34mdrv5sm8rPJfes+4JAG3bmqVNm6L1pCTz/ubMMZ/BV1+ZIaHFWVbRxZOL27PHvOcpU8xnfeaZ0qBBJhR16FCBUXeWCZhLlkh//GGGRJ5xhgnVFT4lKN+0i8WLTU/n4sVF4bVDB9OL2bevaSP1jn35wDJlZkoffii9/rq0dKkZzun5LD3DWtu2NZ/34cMlL5TtWd+7VxoyxFzrrU6ditdwMuGcIB/hvA5UFm0HlUG7QWXQboJXbq703XdFvSC7Cie2a9fOfGG97DLTw+QPeXnmAsPFz0fbtevIdUuHDuXJssKVm2tTng8mM4uLM71hxQNOQoI0dKjpDfMMyywoMNsUFBStb90qff21uSDzxiNmm05ONiHGMx1/8aVOHRNalywxQWLJEhMKj1S/vglDZ55pls6dTbBMT/cMvyy63b5dWr7cnEOXe+QEeLbCy+wcoX17E5p79zbrbdqU/e9rWSbYvvaaCUDluehzZKT5XI8lNla66Sbp1lsr30tlWeaz27bNBOmzy7h6A+cEAQAA4KgiIsxf6IcMkV56yZwrlZ9vhgKG+PnEmPBwMxSvQYOjb+N0FmjWrDneL7OWZerLzTWLy2W+FLvNZHLedbfbhKg//zQ9VH/+aZaNG02gkExgOf98E3x69jRh43g6d5b+/ndznA0bTBiaPdtMpOEJbuUVGiqdcoo5P2vdOhOM9uyRPvnELJIZdmmzHT+E1Klj/s08y2mnmc/p+++lBQtMfStXFl1HbPJk8zqbzfTstG9fNFFJerrp9fnjj6L9t2olXX21+bw8n+uaNUWf69atRQEoMVFq3tz0bnluHQ5zbtnvv0uPPGKGWo4dK912W9mTfezfb/a7bp0ZLlr8QtfbthUdKz6++CQl1QMhCAAAIIiEhEjduwe6imOz2Ux4Cg83X4CPpUUL06tSXF6emaAiLMzMgHgidXjOCRs3rug8q61bS39h37rV9Fy0bm3CyWmnST16mCGZ4eFF+8zNNb1ECxeaiS4WLSoKbJJ5vykpJjSmpJilbVsT4I42jO7CC80imWDxww8mEC1bZkLMgQMmZGzeLM2aVfK1kZFm6OPVV5vP0bP/Nm3M8LriPBOFJCcf/Typyy83E2088IDpwXr8cenFF81wy3r1SgbWgweP/29Qr57pZcvLK/k5BjtCEAAAAKpUePhxZkGspMjIY0/kUZ4JBSIiiobB3XWX6eVau9b0GKWkmF6hE1G3rjRihFk89u0zYWj1anO7Zo3pQbr0UmnkyOMHTQ/PRCHHEhJijj18uJnYY9IkE8aefrrs7Zs0MYGrefPSwwsbNqxewac4QhAAAABqhMrMqGa3+yewFZeYaJY+ffx7nOJsNjMEcdgw0/v06qvmvKTiE1i0auW/c9ECjRAEAAAA1FA2m5mMYujQQFdStar9NagAAAAAoCIIQQAAAABqFEIQAAAAgBqFEAQAAACgRiEEAQAAAKhRCEEAAAAAahRCEAAAAIAahRAEAAAAoEYhBAEAAACoUQhBAAAAAGoUQhAAAACAGoUQBAAAAKBGIQQBAAAAqFEIQQAAAABqFEIQAAAAgBqFEAQAAACgRiEEAQAAAKhRCEEAAAAAahRHoAs4EZZlSZLS09MDXInkdDqVnZ2t9PR0hYaGBrocVCO0HVQG7QaVQbtBZdF2UBlV3W48mcCTEY6lWoegjIwMSVKjRo0CXAkAAACAYJCRkaH4+PhjbmOzyhOVgpTb7dbOnTsVGxsrm80W0FrS09PVqFEjbdu2TXFxcQGtBdULbQeVQbtBZdBuUFm0HVRGVbcby7KUkZGhlJQUhYQc+6yfat0TFBISooYNGwa6jBLi4uL44YBKoe2gMmg3qAzaDSqLtoPKqMp2c7weIA8mRgAAAABQoxCCAAAAANQohCAfCQ8P1/3336/w8PBAl4JqhraDyqDdoDJoN6gs2g4qI5jbTbWeGAEAAAAAKoqeIAAAAAA1CiEIAAAAQI1CCAIAAABQoxCCAAAAANQohCAf+b//+z81bdpUEREROv3007VkyZJAl4Qg8uijj6pHjx6KjY1VvXr1NHz4cK1du7bENrm5uRo7dqwSEhIUExOjCy+8UHv27AlQxQhGjz32mGw2m8aPH+99jHaDo9mxY4cuu+wyJSQkKDIyUp06ddIvv/zifd6yLE2YMEHJycmKjIxU//79tX79+gBWjEBzuVy677771KxZM0VGRqpFixZ68MEHVXwOLdoNvv/+ew0bNkwpKSmy2WyaOXNmiefL00YOHjyoUaNGKS4uTrVq1dJVV12lzMzMKnwXhCCf+PDDD3Xrrbfq/vvv17Jly9SlSxcNHDhQe/fuDXRpCBILFizQ2LFjtXjxYqWmpsrpdOrcc89VVlaWd5tbbrlFX3zxhaZPn64FCxZo586duuCCCwJYNYLJ0qVLNWXKFHXu3LnE47QblOXQoUPq3bu3QkNDNXv2bK1evVpPP/20ateu7d3miSee0PPPP6+XX35ZP//8s6KjozVw4EDl5uYGsHIE0uOPP67JkyfrxRdf1Jo1a/T444/riSee0AsvvODdhnaDrKwsdenSRf/3f/9X5vPlaSOjRo3SH3/8odTUVH355Zf6/vvvde2111bVWzAsnLDTTjvNGjt2rPe+y+WyUlJSrEcffTSAVSGY7d2715JkLViwwLIsy0pLS7NCQ0Ot6dOne7dZs2aNJcn66aefAlUmgkRGRobVqlUrKzU11TrrrLOsm2++2bIs2g2O7o477rDOOOOMoz7vdrutpKQk68knn/Q+lpaWZoWHh1vvv/9+VZSIIDR06FDryiuvLPHYBRdcYI0aNcqyLNoNSpNkzZgxw3u/PG1k9erVliRr6dKl3m1mz55t2Ww2a8eOHVVWOz1BJyg/P1+//vqr+vfv730sJCRE/fv3108//RTAyhDMDh8+LEmqU6eOJOnXX3+V0+ks0Y7atm2rxo0b046gsWPHaujQoSXah0S7wdF9/vnn6t69uy6++GLVq1dPXbt21auvvup9ftOmTdq9e3eJthMfH6/TTz+dtlOD9erVS99++63WrVsnSVqxYoUWLlyowYMHS6Ld4PjK00Z++ukn1apVS927d/du079/f4WEhOjnn3+uslodVXakk9T+/fvlcrlUv379Eo/Xr19ff/75Z4CqQjBzu90aP368evfurY4dO0qSdu/erbCwMNWqVavEtvXr19fu3bsDUCWCxQcffKBly5Zp6dKlpZ6j3eBoNm7cqMmTJ+vWW2/V3XffraVLl2rcuHEKCwvT6NGjve2jrN9dtJ2a684771R6erratm0ru90ul8ulhx9+WKNGjZIk2g2OqzxtZPfu3apXr16J5x0Oh+rUqVOl7YgQBFSxsWPHatWqVVq4cGGgS0GQ27Ztm26++WalpqYqIiIi0OWgGnG73erevbseeeQRSVLXrl21atUqvfzyyxo9enSAq0Ow+uijj/Tee+9p2rRp6tChg5YvX67x48crJSWFdoOTDsPhTlDdunVlt9tLzca0Z88eJSUlBagqBKsbb7xRX375pebNm6eGDRt6H09KSlJ+fr7S0tJKbE87qtl+/fVX7d27V6eeeqocDoccDocWLFig559/Xg6HQ/Xr16fdoEzJyclq3759icfatWunrVu3SpK3ffC7C8X95z//0Z133qlLL71UnTp10r/+9S/dcsstevTRRyXRbnB85WkjSUlJpSYPKygo0MGDB6u0HRGCTlBYWJi6deumb7/91vuY2+3Wt99+q549ewawMgQTy7J04403asaMGfruu+/UrFmzEs9369ZNoaGhJdrR2rVrtXXrVtpRDdavXz+tXLlSy5cv9y7du3fXqFGjvOu0G5Sld+/epabhX7dunZo0aSJJatasmZKSkkq0nfT0dP3888+0nRosOztbISElvxra7Xa53W5JtBscX3naSM+ePZWWlqZff/3Vu813330nt9ut008/veqKrbIpGE5iH3zwgRUeHm69+eab1urVq61rr73WqlWrlrV79+5Al4Ygcf3111vx8fHW/PnzrV27dnmX7Oxs7zbXXXed1bhxY+u7776zfvnlF6tnz55Wz549A1g1glHx2eEsi3aDsi1ZssRyOBzWww8/bK1fv9567733rKioKOvdd9/1bvPYY49ZtWrVsj777DPr999/t84//3yrWbNmVk5OTgArRyCNHj3aatCggfXll19amzZtsj799FOrbt261n//+1/vNrQbZGRkWL/99pv122+/WZKsZ555xvrtt9+sLVu2WJZVvjYyaNAgq2vXrtbPP/9sLVy40GrVqpU1cuTIKn0fhCAfeeGFF6zGjRtbYWFh1mmnnWYtXrw40CUhiEgqc5k6dap3m5ycHOuGG26wateubUVFRVkjRoywdu3aFbiiEZSODEG0GxzNF198YXXs2NEKDw+32rZta73yyislnne73dZ9991n1a9f3woPD7f69etnrV27NkDVIhikp6dbN998s9W4cWMrIiLCat68uXXPPfdYeXl53m1oN5g3b16Z32lGjx5tWVb52siBAweskSNHWjExMVZcXJx1xRVXWBkZGVX6PmyWVewywAAAAABwkuOcIAAAAAA1CiEIAAAAQI1CCAIAAABQoxCCAAAAANQohCAAAAAANQohCAAAAECNQggCAAAAUKMQggAAAADUKIQgAECNYbPZNHPmzECXAQAIMEIQAKBKjBkzRjabrdQyaNCgQJcGAKhhHIEuAABQcwwaNEhTp04t8Vh4eHiAqgEA1FT0BAEAqkx4eLiSkpJKLLVr15ZkhqpNnjxZgwcPVmRkpJo3b66PP/64xOtXrlypc845R5GRkUpISNC1116rzMzMEtu88cYb6tChg8LDw5WcnKwbb7yxxPP79+/XiBEjFBUVpVatWunzzz/3Pnfo0CGNGjVKiYmJioyMVKtWrUqFNgBA9UcIAgAEjfvuu08XXnihVqxYoVGjRunSSy/VmjVrJElZWVkaOHCgateuraVLl2r69On65ptvSoScyZMna+zYsbr22mu1cuVKff7552rZsmWJY0yaNEmXXHKJfv/9dw0ZMkSjRo3SwYMHvcdfvXq1Zs+erTVr1mjy5MmqW7du1X0AAIAqYbMsywp0EQCAk9+YMWP07rvvKiIiosTjd999t+6++27ZbDZdd911mjx5sve5v/3tbzr11FP10ksv6dVXX9Udd9yhbdu2KTo6WpI0a9YsDRs2TDt37lT9+vXVoEEDXXHFFXrooYfKrMFms+nee+/Vgw8+KMkEq5iYGM2ePVuDBg3Seeedp7p16+qNN97w06cAAAgGnBMEAKgyZ599domQI0l16tTxrvfs2bPEcz179tTy5cslSWvWrFGXLl28AUiSevfuLbfbrbVr18pms2nnzp3q16/fMWvo3Lmzdz06OlpxcXHau3evJOn666/XhRdeqGXLluncc8/V8OHD1atXr0q9VwBA8CIEAQCqTHR0dKnhab4SGRlZru1CQ0NL3LfZbHK73ZKkwYMHa8uWLZo1a5ZSU1PVr18/jR07Vk899ZTP6wUABA7nBAEAgsbixYtL3W/Xrp0kqV27dlqxYoWysrK8zy9atEghISFq06aNYmNj1bRpU3377bcnVENiYqJGjx6td999V88995xeeeWVE9ofACD40BMEAKgyeXl52r17d4nHHA6Hd/KB6dOnq3v37jrjjDP03nvvacmSJXr99dclSaNGjdL999+v0aNHa+LEidq3b59uuukm/etf/1L9+vUlSRMnTtR1112nevXqafDgwcrIyNCiRYt00003lau+CRMmqFu3burQoYPy8vL05ZdfekMYAODkQQgCAFSZr7/+WsnJySUea9Omjf78809JZua2Dz74QDfccIOSk5P1/vvvq3379pKkqKgozZkzRzfffLN69OihqKgoXXjhhXrmmWe8+xo9erRyc3P17LPP6vbbb1fdunV10UUXlbu+sLAw3XXXXdq8ebMiIyN15pln6oMPPvDBOwcABBNmhwMABAWbzaYZM2Zo+PDhgS4FAHCS45wgAAAAADUKIQgAAABAjcI5QQCAoMDobABAVaEnCAAAAECNQggCAAAAUKMQggAAAADUKIQgAAAAADUKIQgAAABAjUIIAgAAAFCjEIIAAAAA1CiEIAAAAAA1yv8DWiL4k30hFzAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss', color='blue')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss', color='orange')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15407    0\n",
       "2181     2\n",
       "8038     0\n",
       "5684     3\n",
       "7429     1\n",
       "        ..\n",
       "10522    4\n",
       "9183     1\n",
       "9686     1\n",
       "4676     2\n",
       "3932     0\n",
       "Name: price, Length: 3140, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Root Mean Squared Error (RMSE): 0.8685957625536258\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=RANDOM_STATE)\n",
    "# model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=500, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step\n"
     ]
    }
   ],
   "source": [
    "logits = model.predict(X_val)\n",
    "y_p = np.argmax(logits, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Root Mean Squared Error (RMSE): 0.9702583541950826\n"
     ]
    }
   ],
   "source": [
    "y_val_class = np.argmax(y_val, axis=1)\n",
    "rmse = np.sqrt(mean_squared_error(y_p, y_val_class))\n",
    "print(\"\\nRoot Mean Squared Error (RMSE):\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5522292993630573\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.82      0.76       540\n",
      "           1       0.46      0.49      0.48       524\n",
      "           2       0.39      0.43      0.41       513\n",
      "           3       0.46      0.40      0.43       556\n",
      "           4       0.47      0.43      0.45       463\n",
      "           5       0.82      0.71      0.76       544\n",
      "\n",
      "    accuracy                           0.55      3140\n",
      "   macro avg       0.55      0.55      0.55      3140\n",
      "weighted avg       0.56      0.55      0.55      3140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Best Parameters: {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Accuracy: 0.6184713375796178\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83       539\n",
      "           1       0.55      0.61      0.57       537\n",
      "           2       0.51      0.47      0.49       508\n",
      "           3       0.50      0.55      0.52       557\n",
      "           4       0.52      0.46      0.49       477\n",
      "           5       0.80      0.78      0.79       522\n",
      "\n",
      "    accuracy                           0.62      3140\n",
      "   macro avg       0.62      0.62      0.62      3140\n",
      "weighted avg       0.62      0.62      0.62      3140\n",
      "\n",
      "\n",
      "Root Mean Squared Error (RMSE): 0.8442386235556774\n"
     ]
    }
   ],
   "source": [
    "X = modified_data_train.drop(columns=['price'])\n",
    "y = modified_data_train['price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y)\n",
    "\n",
    "numerical_features = X_train.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "\n",
    "# X_train[numerical_features] = scaler.fit_transform(X_train[numerical_features])\n",
    "# X_test[numerical_features] = scaler.transform(X_test[numerical_features])\n",
    "\n",
    "model_xgb = XGBClassifier(objective='reg:squarederror', num_class=y.nunique(), random_state=RANDOM_STATE)\n",
    "param_grid = {\n",
    "    'max_depth': [7],\n",
    "    'learning_rate': [0.1],\n",
    "    'n_estimators': [200],\n",
    "    'subsample': [0.8],\n",
    "    'colsample_bytree': [0.8]\n",
    "}\n",
    "grid_search = GridSearchCV(estimator=model_xgb, param_grid=param_grid, scoring='neg_mean_squared_error', cv=5, verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"\\nRoot Mean Squared Error (RMSE):\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Tools\\miniconda\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Root Mean Squared Error (RMSE): 0.8590099470739407\n"
     ]
    }
   ],
   "source": [
    "modified_data = eng_train_data.copy()\n",
    "\n",
    "# Select the features for clustering\n",
    "geo_features = train_data[['longitude', 'latitude']]\n",
    "\n",
    "# Apply K-Means clustering with 5 clusters\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "\n",
    "modified_data['location_cluster'] = kmeans.fit_predict(geo_features)\n",
    "X = modified_data.drop(columns=['price'])\n",
    "y = modified_data['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y)\n",
    "\n",
    "testing_model = XGBClassifier(colsample_bytree = 0.8, learning_rate =  0.1, max_depth = 7, n_estimators = 200, subsample = 0.8, objective='reg:squarederror', num_class=y.nunique(), random_state=RANDOM_STATE)\n",
    "testing_model.fit(X_train, y_train)\n",
    "y_pred = testing_model.predict(X_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"\\nRoot Mean Squared Error (RMSE):\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)  # First hidden layer\n",
    "        self.relu1 = nn.ReLU()\n",
    "        # self.fc2 = nn.Linear(128, 64)  # Second hidden layer\n",
    "        # self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(128, output_size)  # Output layer\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        # x = self.fc2(x)\n",
    "        # x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = torch.load('nn_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>host_response_rate</th>\n",
       "      <th>host_acceptance_rate</th>\n",
       "      <th>host_is_superhost</th>\n",
       "      <th>host_listings_count</th>\n",
       "      <th>host_total_listings_count</th>\n",
       "      <th>host_verifications</th>\n",
       "      <th>host_has_profile_pic</th>\n",
       "      <th>...</th>\n",
       "      <th>property_type_encoded</th>\n",
       "      <th>room_type_encoded</th>\n",
       "      <th>amenity_score</th>\n",
       "      <th>neighbourhood_group_encoded</th>\n",
       "      <th>weighted_availability</th>\n",
       "      <th>log_minimum_nights</th>\n",
       "      <th>min_nights_accommodates_interaction</th>\n",
       "      <th>location_cluster</th>\n",
       "      <th>weighted_review_score</th>\n",
       "      <th>availability_acceptance_interaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3917</td>\n",
       "      <td>40.744620</td>\n",
       "      <td>-73.904520</td>\n",
       "      <td>100.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "      <td>68.0</td>\n",
       "      <td>3.433987</td>\n",
       "      <td>180</td>\n",
       "      <td>2</td>\n",
       "      <td>4.972</td>\n",
       "      <td>6188.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1885</td>\n",
       "      <td>40.753407</td>\n",
       "      <td>-73.934995</td>\n",
       "      <td>99.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>727.0</td>\n",
       "      <td>1336.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>68.0</td>\n",
       "      <td>3.433987</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1564.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1305</td>\n",
       "      <td>40.677090</td>\n",
       "      <td>-73.943810</td>\n",
       "      <td>100.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>68.0</td>\n",
       "      <td>3.433987</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>4.829</td>\n",
       "      <td>6188.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19328</td>\n",
       "      <td>40.795760</td>\n",
       "      <td>-73.971570</td>\n",
       "      <td>70.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.433987</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>4.800</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16511</td>\n",
       "      <td>40.713590</td>\n",
       "      <td>-73.955400</td>\n",
       "      <td>100.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>16.2</td>\n",
       "      <td>3.433987</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>4.869</td>\n",
       "      <td>1215.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6722</th>\n",
       "      <td>7205</td>\n",
       "      <td>40.637960</td>\n",
       "      <td>-73.951360</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>69.0</td>\n",
       "      <td>3.433987</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>4.712</td>\n",
       "      <td>6900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6723</th>\n",
       "      <td>3954</td>\n",
       "      <td>40.823720</td>\n",
       "      <td>-73.945460</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3.433987</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>4.720</td>\n",
       "      <td>26.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6724</th>\n",
       "      <td>1358</td>\n",
       "      <td>40.755094</td>\n",
       "      <td>-73.937260</td>\n",
       "      <td>99.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>727.0</td>\n",
       "      <td>1336.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3.433987</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>966.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6725</th>\n",
       "      <td>2793</td>\n",
       "      <td>40.781580</td>\n",
       "      <td>-73.984780</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>31.6</td>\n",
       "      <td>3.433987</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>4.850</td>\n",
       "      <td>3160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6726</th>\n",
       "      <td>865</td>\n",
       "      <td>40.695890</td>\n",
       "      <td>-73.760830</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>3</td>\n",
       "      <td>69.0</td>\n",
       "      <td>3.433987</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>4.721</td>\n",
       "      <td>6900.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6727 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id   latitude  longitude  host_response_rate  host_acceptance_rate  \\\n",
       "0      3917  40.744620 -73.904520               100.0                  91.0   \n",
       "1      1885  40.753407 -73.934995                99.0                  23.0   \n",
       "2      1305  40.677090 -73.943810               100.0                  91.0   \n",
       "3     19328  40.795760 -73.971570                70.0                  37.0   \n",
       "4     16511  40.713590 -73.955400               100.0                  75.0   \n",
       "...     ...        ...        ...                 ...                   ...   \n",
       "6722   7205  40.637960 -73.951360               100.0                 100.0   \n",
       "6723   3954  40.823720 -73.945460                 0.0                  33.0   \n",
       "6724   1358  40.755094 -73.937260                99.0                  23.0   \n",
       "6725   2793  40.781580 -73.984780               100.0                 100.0   \n",
       "6726    865  40.695890 -73.760830               100.0                 100.0   \n",
       "\n",
       "      host_is_superhost  host_listings_count  host_total_listings_count  \\\n",
       "0                     0                  1.0                       12.0   \n",
       "1                     0                727.0                     1336.0   \n",
       "2                     0                  1.0                        1.0   \n",
       "3                     0                 36.0                       79.0   \n",
       "4                     0                  1.0                        1.0   \n",
       "...                 ...                  ...                        ...   \n",
       "6722                  0                  2.0                        2.0   \n",
       "6723                  0                  7.0                        8.0   \n",
       "6724                  0                727.0                     1336.0   \n",
       "6725                  0                  1.0                        3.0   \n",
       "6726                  0                  3.0                        3.0   \n",
       "\n",
       "      host_verifications  host_has_profile_pic  ...  property_type_encoded  \\\n",
       "0                      0                     0  ...                      9   \n",
       "1                      0                     0  ...                      2   \n",
       "2                      0                     0  ...                     10   \n",
       "3                      0                     0  ...                      6   \n",
       "4                      0                     0  ...                      6   \n",
       "...                  ...                   ...  ...                    ...   \n",
       "6722                   0                     0  ...                      2   \n",
       "6723                   0                     0  ...                      2   \n",
       "6724                   0                     0  ...                      2   \n",
       "6725                   0                     0  ...                      6   \n",
       "6726                   0                     0  ...                      1   \n",
       "\n",
       "      room_type_encoded  amenity_score  neighbourhood_group_encoded  \\\n",
       "0                     4             49                            3   \n",
       "1                     2             15                            3   \n",
       "2                     4             10                            4   \n",
       "3                     4             17                            5   \n",
       "4                     4             44                            4   \n",
       "...                 ...            ...                          ...   \n",
       "6722                  2             64                            4   \n",
       "6723                  2             13                            5   \n",
       "6724                  2             15                            3   \n",
       "6725                  4             31                            5   \n",
       "6726                  2             46                            3   \n",
       "\n",
       "      weighted_availability  log_minimum_nights  \\\n",
       "0                      68.0            3.433987   \n",
       "1                      68.0            3.433987   \n",
       "2                      68.0            3.433987   \n",
       "3                       0.0            3.433987   \n",
       "4                      16.2            3.433987   \n",
       "...                     ...                 ...   \n",
       "6722                   69.0            3.433987   \n",
       "6723                    0.8            3.433987   \n",
       "6724                   42.0            3.433987   \n",
       "6725                   31.6            3.433987   \n",
       "6726                   69.0            3.433987   \n",
       "\n",
       "      min_nights_accommodates_interaction  location_cluster  \\\n",
       "0                                     180                 2   \n",
       "1                                      30                 3   \n",
       "2                                      60                 4   \n",
       "3                                      30                 2   \n",
       "4                                      60                 3   \n",
       "...                                   ...               ...   \n",
       "6722                                   60                 4   \n",
       "6723                                   30                 2   \n",
       "6724                                   30                 3   \n",
       "6725                                   60                 3   \n",
       "6726                                   60                 1   \n",
       "\n",
       "      weighted_review_score  availability_acceptance_interaction  \n",
       "0                     4.972                               6188.0  \n",
       "1                     0.000                               1564.0  \n",
       "2                     4.829                               6188.0  \n",
       "3                     4.800                                  0.0  \n",
       "4                     4.869                               1215.0  \n",
       "...                     ...                                  ...  \n",
       "6722                  4.712                               6900.0  \n",
       "6723                  4.720                                 26.4  \n",
       "6724                  0.000                                966.0  \n",
       "6725                  4.850                               3160.0  \n",
       "6726                  4.721                               6900.0  \n",
       "\n",
       "[6727 rows x 52 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = modified_data.copy()\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X_test = torch.tensor(X, dtype=torch.float32)\n",
    "X_test = X_test.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.8354, 2.8660, 2.8930, 2.8432, 2.9152, 2.8341],\n",
       "        [3.1861, 2.9097, 3.1231, 3.0448, 3.0301, 3.0887],\n",
       "        [1.2974, 1.2915, 1.3520, 1.3342, 1.3840, 1.2861],\n",
       "        ...,\n",
       "        [3.0325, 2.7761, 2.9778, 2.9029, 2.9037, 2.9572],\n",
       "        [1.6169, 1.6223, 1.6691, 1.6439, 1.6896, 1.6089],\n",
       "        [4.0472, 4.0452, 4.0600, 4.0269, 4.0618, 4.0201]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = nn_model(X_test)\n",
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
